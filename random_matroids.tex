\chapter{Random matroid generation}

One goal for this project is to create the Julia library \mono{Matroids.jl}, which will supply functionality for generating and interacting with random matroids. In the preparatory project delivered fall of 2022, I implemented Knuth's 1974 algorithm for the random generation of arbitrary matroids via the erection of closed sets \cite{knuth-1975}. With this, I was able to randomly generate matroids with a universe size $n$ of about 12, but for larger values of $n$ my implementation was unbearably slow. In this chapter, Knuth's method for random matroid construction will be described, along with the steps I have taken to speed up my initial, naïve implementation. The random generation of other specific types of matroids is discussed as well.

\section{Knuth's matroid construction}
\pr{Knuth-Matroid} (given in Algorithm~\ref{alg:knuth}) accepts the ground set $E$ and a list of enlargements $\mathrm{X}$, and produces the matroid over $E$ where each set in $\mathrm{X}[r]$ is a closed set of rank $r$. The output is the list $\mathrm{F} = [F_0, \ldots, F_r]$, where $r$ is the final rank of $\mathfrak{M}$ and $F_i$ is the set of closed sets of rank $i$. In the paper, Knuth shows that $\bigcup_{i=0}^r \mathrm{F}[r] = \mathcal{F}$, and so the resulting matroid is $\mathfrak{M} = (E, \mathcal{F})$.

The algorithm proceeds in a bottom-up manner, starting with the single closed set of rank 0 (the empty set) and for each rank $r+1$ adds the covers of the closed sets of rank $r$. The covers of a closed set $A$ of rank $r$ is simply all sets obtained by adding one more element from $E$ to $A$. The covers are generated with the helper method \pr{Generate-Covers}(\mathrm{F}, r, E).

\begin{tcolorbox}[pseudo/filled, colback=lighttan]
  \begin{pseudo}*
    \hd{Generate-Covers}(\mathrm{F}, r, E) \\
    \pr{Append}(\mathrm{F}, \{ A \cup \{a\} : A \in \mathrm{F}[r], a \in E \setminus A \})
  \end{pseudo}
\end{tcolorbox}

Given no enlargements ($\mathrm{X} = []$), the resulting matroid is the uniform matroid of rank $|E|$. Arbitrary matroids can be generated by supplying different lists $\mathrm{X}$. \pr{Enlarge}(\mathrm{F}[r+1], \mathrm{X}[r+1]) simply adds all the sets in $\mathrm{X}[r+1]$ to $\mathrm{F}[r+1]$.

\pr{Superpose}(\mathrm{F}[r+1], F[r]) ensures that the newly enlarged set of closed sets of rank $r+1$ is valid. If $F_{r+1}$ contains two sets $A,B$ whose intersection $A \cap B \not \subseteq C$, for some $C \in F_{r}$, replace $A,B$ with $A \cup B$. Repeat until no two sets exist in $F_{r+1}$ whose intersection is not contained within some set $C \in F_{r}$.

\begin{tcolorbox}[pseudo/filled, colback=lighttan, float*=ht!]
  \begin{pseudo}[indent-mark]*
    \hd{Superpose}({F_{r+1},F_r}) \\
    for $A \in F_{r+1}$ \\+
    for $B \in F_{r+1}$ \\+
    flag $\leftarrow$ \texttt{true} \\
    for $C \in F_r$ \\+
    if $A \cap B \subseteq C$ \\+
    flag $\leftarrow$ \texttt{false} \\--
    \\
    if flag = \texttt{true} \\+
    $F_{r+1} \leftarrow F_{r+1} \setminus \{A, B \}$ \\
    $F_{r+1} \leftarrow F_{r+1} \cup \{A \cup B \}$
  \end{pseudo}
\end{tcolorbox}

\begin{algorithm}[float*=ht!]{\pr{Knuth-Matroid}(E, \mathrm{X})}{knuth}

  \textbf{Input:}     \tab The ground set of elements $E$, and a list of enlargements $\mathrm{X}$.

  \textbf{Output:}    \tab The list of closed sets of the resulting matroid grouped by rank, \\
  \mbox{}\tab $\mathrm{F} = [F_0, \ldots, F_r]$, where $F_i$ is the set of closed sets of rank $i$.

  \begin{pseudo}[label=\small\arabic*, indent-mark, line-height=1.2]
    $r = 0, \mathrm{F} = [\{ \emptyset \}]$ \\
    while true  \\+
    % $\mathrm{F}[r+1] = \{ A \cup \{a\} : A \in \mathrm{F}[r], a \in E \setminus A \}$ \\
    $\pr{Generate-Covers}(\mathrm{F}, r, E)$ \\
    $\mathrm{F}[r+1] = \mathrm{F}[r+1] \cup \mathrm{X}[r+1]$ \\
    \pr{Superpose}(\mathrm{F}[r+1], \mathrm{F}[r]) \\

    if $E \not \in F[r+1]$ \\+
    $r \leftarrow r+1$ \\-
    else \\+
    return $\mathrm{F}$

  \end{pseudo}

\end{algorithm}

The pseudocode given in this section corresponds closely to the naïve Julia implementation whose poor performance was mentioned at the beginning of the chapter. It should already be clear that this brute force implementation leads to poor performance -- for instance, the \pr{Superpose} method uses a triply nested for loop! Subpar stuff. Section~\ref{sec:improving-performance} describes the engineering work done to create a more performant implementation.

\subsection{Randomized KMC}
\skelpars[3]

\subsection{Improving performance}
\label{sec:improving-performance}
When recreating Knuth's table of observed mean values for the randomly generated matroids, some of the latter configurations of $n$ and $(p_1, p_2, \ldots)$ was unworkably slow, presumably due to the naïve implementation of the algorithm. Table~\ref{tab:perf_v1} shows the performance of this first implementation.

\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{randomized\_kmc\_v1}$.}
  \label{tab:perf_v1}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
        10 & (0, 6, 0)    & 100 & 0.0689663   & 0.0106786 & 147.237 MiB \\
        10 & (0, 5, 1)    & 100 & 0.1197194   & 0.0170734 & 251.144 MiB \\
        10 & (0, 5, 2)    & 100 & 0.0931822   & 0.0144022 & 203.831 MiB \\
        10 & (0, 6, 1)    & 100 & 0.0597314   & 0.0094902 & 132.460 MiB \\
        10 & (0, 4, 2)    & 100 & 0.1924601   & 0.0284532 & 406.131 MiB \\
        10 & (0, 3, 3)    & 100 & 0.3196838   & 0.0463972 & 678.206 MiB \\
        10 & (0, 0, 6)    & 100 & 1.1420602   & 0.1671325 & 2.356 GiB   \\
        10 & (0, 1, 1, 1) & 100 & 2.9283978   & 0.3569357 & 5.250 GiB   \\
        13 & (0, 6, 0)    & 10  & 104.0171128 & 9.9214449 & 161.523 GiB \\
        13 & (0, 6, 2)    & 10  & 11.4881308  & 1.3777947 & 20.888 GiB  \\
        16 & (6, 0, 0)    & 1   & -           & -         & -           \\
      \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table*}

The performance was measured using Julia's $\texttt{@timed}$ macro \footnote{\href{https://docs.julialang.org/en/v1/base/base/\#Base.@timed}{https://docs.julialang.org/en/v1/base/base/\#Base.@timed}}, which returns the time it takes to execute a function call, how much of that time was spent in garbage collection and the size of the memory allocated. As is evident from the data, larger matroids are computationally quite demanding to compute with the current approach, and the time and space requirements scales exponentially with $n$. Can we do better? As it turns out, we can; after the improvements outlined in this section, we will be able to generate matroids over universes as large as $n=128$ in a manner of seconds and megabytes.

\subsubsection{Representing sets as binary numbers}
The first improvement we will attempt is to represent our families as sets of hexadecimal numbers, instead of sets of sets of numbers. Sets are represented using Julia's native $\texttt{Set}$ type \footnote{\href{https://docs.julialang.org/en/v1/base/collections/\#Base.Set}{https://docs.julialang.org/en/v1/base/collections/\#Base.Set}}. \skelpar{Skrive mer om hvordan Set\{Set\{Integer\}\} lagres i minnet og fordelene med å gå over til Set\{Integer\}.}

The idea is to define a family of closed sets of the same rank as \mono{Set}\{\mono{UInt16}\}. Using \mono{UInt16} we can support ground sets of size up to 16. Each 16-bit number represents a set in the family. For instance, the set $\{ 2,5,7 \}$ is represented by $$164 = 0\rm{x}00\rm{a}4 = 0\rm{b}0000000010100100 = 2^7+2^5+2^2.$$ At either end we have $\emptyset \equiv 0\rm{x}0000$ and $E \equiv 0\rm{xffff}$ (if $n = 16$). Set operations have equivalent binary operations; intersection corresponds to bitwise AND, union to bitwise OR and the set difference between sets $A$ and $B$ to the bitwise OR of $A$ and the complement of $B$. Subset equality is also simple to implement: $A \subseteq B \iff A \cap B = A.$ \skelpar{Beskrive KMC v2. Kode? Pseudokode? Putte i appendix? Finn ut.}

\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{randomized\_kmc\_v2}$.}
  \label{tab:perf_v2}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0] & 100 & 0.0010723 & 0.0001252 & 1.998 MiB \\ 
      10 & [0, 5, 1] & 100 & 0.0017543 & 0.0001431 & 3.074 MiB \\ 
      10 & [0, 5, 2] & 100 & 0.0008836 & 0.0001075 & 2.072 MiB \\ 
      10 & [0, 6, 1] & 100 & 0.0007294 & 6.73e-5 & 1.700 MiB \\ 
      10 & [0, 4, 2] & 100 & 0.0020909 & 0.0001558 & 3.889 MiB \\ 
      10 & [0, 3, 3] & 100 & 0.0024636 & 0.0002139 & 4.530 MiB \\ 
      10 & [0, 0, 6] & 100 & 0.007082 & 0.0004801 & 9.314 MiB \\ 
      10 & [0, 1, 1, 1] & 100 & 0.0132477 & 0.0008307 & 17.806 MiB \\ 
      13 & [0, 6, 0] & 10 & 0.042543 & 0.0014988 & 31.964 MiB \\ 
      13 & [0, 6, 2] & 10 & 0.0183313 & 0.0012176 & 21.062 MiB \\ 
      16 & [0, 6, 0] & 10 & 1.2102877 & 0.0146129 & 450.052 MiB \\ 
      \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table*}

It is clear that representing closed sets using binary numbers is a substantial improvement -- we are looking at performance increases of 100x-1000x across the board.


\subsubsection{Sorted superpose}
Can we improve the running time of the algorithm further? One idea might be to perform the superpose operation in descending order based on the size of the sets. This should result in fewer calls, as the bigger sets will "eat" the smaller sets that fully overlap with them in the early iterations, however, the repeated sorting of the sets might negate this performance gain. \skelpar{KANSKJE: Skrive bedre om idéen bak sorted superpose.} 

Unfortunately, as Table~\ref{tab:perf_v3} shows, this implementation is a few times slower and more space demanding than the previous implementation. This is likely due to the fact that an ordered list is more space inefficient than the hashmap-based \mono{Set}.

\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{randomized\_kmc\_v3}$.}
  \label{tab:perf_v3}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0] & 100 & 0.0023382 & 0.0001494 & 4.042 MiB \\
      10 & [0, 5, 1] & 100 & 0.001853 & 0.0001433 & 4.383 MiB \\
      10 & [0, 5, 2] & 100 & 0.0017845 & 0.0001341 & 4.043 MiB \\
      10 & [0, 6, 1] & 100 & 0.0015145 & 0.0001117 & 3.397 MiB \\
      10 & [0, 4, 2] & 100 & 0.0030704 & 0.0002125 & 6.385 MiB \\
      10 & [0, 3, 3] & 100 & 0.0037838 & 0.0002514 & 7.018 MiB \\
      10 & [0, 0, 6] & 100 & 0.008903 & 0.000557 & 14.159 MiB \\
      10 & [0, 1, 1, 1] & 100 & 0.0142828 & 0.0008823 & 21.838 MiB \\
      13 & [0, 6, 0] & 10 & 0.0627633 & 0.002094 & 51.492 MiB \\
      13 & [0, 6, 2] & 10 & 0.0106478 & 0.0007704 & 20.774 MiB \\
      16 & [0, 6, 0] & 10 & 0.6070136 & 0.0095656 & 310.183 MiB \\
      \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table*}

\skelpar{Skrive om variansen mellom tilfeldige matroider! @benchmark osv. Histogram}


\subsubsection{Iterative superpose}
So far, we are inserting all covers of $F_r$ into $F_{r+1}$ along with all enlargements, and then running the superpose operation on all of them at once. In the worst case, when no enlargements have been made, $F_{r+1}$ is the set of all $r+1$-sized subsets of $E$, $|F_{r+1}| = {\binom{n}{r+1}}$.  Until this point, the superpose operation was performed with a triply nested \mono{for} loop, comparing each $A,B \in F_{r+1}$ with each $C \in F_r$ to see whether $A\cap B \subseteq C$ or whether $A, B$ should be replaced by $A\cup B$. Thus we were looking at a whopping $\mathcal{O}({\binom{n}{r+1}}^2{\binom{n}{r}})$ operations to perform the superpose part of step $r$.



\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{randomized\_kmc\_v4}$.}
  \label{tab:perf_v4}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \skeltabular[15]
    \end{tabular}
  \end{threeparttable}
\end{table*}

\subsubsection{Rank table}
\skelpars[5]

\subsubsection{Non-redundant cover generation and iterative superpose}
\skelpars[7]

\subsection{Finding independent sets and circuits}
\skelpars[15]

\section{Other kinds of matroids}
\skelpars[1]

\subsection{Uniform matroids}
\skelpars[4]

\subsection{Graphic matroids}
\skelpars[6]

\subsection{Vector matroids}
\skelpars[7]