\chapter{Random matroid generation}

One goal for this project is to create the Julia library \mono{Matroids.jl}, which will supply functionality for generating and interacting with random matroids. In the preparatory project delivered fall of 2022, I implemented Knuth's 1974 algorithm for the random generation of arbitrary matroids via the erection of closed sets \cite{knuth-1975}. With this, I was able to randomly generate matroids with a universe size $n$ of about 12, but for larger values of $n$ my implementation was unbearably slow. In this chapter, Knuth's method for random matroid construction will be described, along with the steps I have taken to speed up my initial, naïve implementation. The random generation of other specific types of matroids is discussed as well.

\section{Knuth's matroid construction (KMC)}
\pr{Knuth-Matroid} (given in Algorithm~\ref{alg:knuth}) accepts the ground set $E$ and a list of enlargements $\mathrm{X}$, and produces the matroid over $E$ where each set in $\mathrm{X}[r]$ is a closed set of rank $r$. The output is the list $\mathrm{F} = [F_0, \ldots, F_r]$, where $r$ is the final rank of $\mathfrak{M}$ and $F_i$ is the set of closed sets of rank $i$. In the paper, Knuth shows that $\bigcup_{i=0}^r \mathrm{F}[r] = \mathcal{F}$, and so the resulting structure $\mathfrak{M} = (E, \mathcal{F})$ is a matroid.

The algorithm proceeds in a bottom-up manner, starting with the single closed set of rank 0 (the empty set) and for each rank $r+1$ adds the covers of the closed sets of rank $r$. The covers of a closed set $A$ of rank $r$ is simply all sets obtained by adding one more element from $E$ to $A$. The covers are generated with the helper method \pr{Generate-Covers}(\mathrm{F}, r, E).

\begin{tcolorbox}[pseudo/boxruled]
  \begin{pseudo}*
    \hd{Generate-Covers}(\mathrm{F}, r, E) \\
    return $\{ A \cup \{a\} : A \in \mathrm{F}[r], a \in E \setminus A \}$
  \end{pseudo}
\end{tcolorbox}

Given no enlargements ($\mathrm{X} = []$), the resulting matroid is the uniform matroid of rank $|E|$. Arbitrary matroids can be generated by supplying different lists $\mathrm{X}$. When enlarging, the sets in $\mathrm{X}[r+1]$ are simply added to $\mathrm{F}[r+1]$.

\pr{Superpose!}(\mathrm{F}[r+1], F[r]) ensures that the newly enlarged set of closed sets of rank $r+1$ is valid. If $F_{r+1}$ contains two sets $A,B$ whose intersection $A \cap B \not \subseteq C$, for some $C \in F_{r}$, replace $A,B$ with $A \cup B$. Repeat until no two sets exist in $F_{r+1}$ whose intersection is not contained within some set $C \in F_{r}$.

\begin{tcolorbox}[pseudo/boxruled, float*=ht!]
  \begin{pseudo}[indent-mark]*
    \hd{Superpose!}({F_{r+1},F_r}) \\
    for $A \in F_{r+1}$ \\+
    for $B \in F_{r+1}$ \\+
    flag $\leftarrow$ \texttt{true} \\
    for $C \in F_r$ \\+
    if $A \cap B \subseteq C$ \\+
    flag $\leftarrow$ \texttt{false} \\--
    \\
    if flag = \texttt{true} \\+
    $F_{r+1} \leftarrow F_{r+1} \setminus \{A, B \}$ \\
    $F_{r+1} \leftarrow F_{r+1} \cup \{A \cup B \}$
  \end{pseudo}
\end{tcolorbox}

\begin{algorithm}[float*=ht!]{\pr{Knuth-Matroid}(E, \mathrm{X})}{knuth}

  \textbf{Input:}     \tab The ground set of elements $E$, and a list of enlargements $\mathrm{X}$.

  \textbf{Output:}    \tab The list of closed sets of the resulting matroid grouped by rank, \\
  \mbox{}\tab $\mathrm{F} = [F_0, \ldots, F_r]$, where $F_i$ is the set of closed sets of rank $i$.

  \begin{pseudo}[label=\small\arabic*, indent-mark, line-height=1.2]
    $r = 0, \mathrm{F} = [\{ \emptyset \}]$ \\
    while true  \\+
    $\pr{Push!}(\mathrm{F}, \pr{Generate-Covers}(\mathrm{F}, r, E))$ \\
    $\mathrm{F}[r+1] = \mathrm{F}[r+1] \cup \mathrm{X}[r+1]$ \\
    \pr{Superpose!}(\mathrm{F}[r+1], \mathrm{F}[r]) \\

    if $E \not \in F[r+1]$ \\+
    $r \leftarrow r+1$ \\-
    else \\+
    return $(E, \mathrm{F})$

  \end{pseudo}

\end{algorithm}


\subsection{Randomized KMC}
In the randomized version of \pr{Knuth-Matroid}, we generate matroids by applying a supplied number of random coarsening steps, instead of enlarging with supplied sets. This is done by applying \pr{Superpose!} immediately after adding the covers, then choosing a random member $A$ of $\mathrm{F}[r+1]$ and a random element $a \in E \setminus A$, replacing $A$ with $A \cup \{a\}$ and finally reapplying \pr{Superpose!}. The parameter $p = (p_1, p_2, \ldots)$ gives the number of such coarsening steps to be applied at each iteration of the algorithm.

The pseudocode given up to this point corresponds closely to the initial Julia implementation, which can be found in Appendix~\ref{apx:randkmcv1}. It should already be clear that this brute force implementation leads to poor performance -- for instance, the \pr{Superpose!} method uses a triply nested for loop, which is a candidate for significant improvement if possible. Section~\ref{sec:improving-performance} describes the engineering work done to create a more performant implementation.

\begin{algorithm}[float*=ht!]{\pr{Randomized-Knuth-Matroid}(E, p)}{rkmc}

  \textbf{Input:}     \tab The ground set of elements $E$, and a list $p = [p_1, p_2, ...]$, where \\
  \mbox{}\tab $p_r$ is the number of coarsening steps to apply at rank $r$ in the \\
  \mbox{}\tab construction.

  \textbf{Output:}    \tab The list of closed sets of the resulting matroid grouped by rank, \\
  \mbox{}\tab $\mathrm{F} = [F_0, \ldots, F_r]$, where $F_i$ is the set of closed sets of rank $i$.

  \begin{pseudo}[label=\small\arabic*, indent-mark, line-height=1.2]
    $r = 0, \mathrm{F} = [\{ \emptyset \}]$ \\
    while true  \\+
      $\pr{Push!}(\mathrm{F}, \pr{Generate-Covers}(\mathrm{F}, r, E))$ \\
      \pr{Superpose!}(\mathrm{F}[r+1], \mathrm{F}[r]) \\
      
      if $E \in \mathrm{F}[r+1]$ return $(E, \mathrm{F})$ \\
      
      while $p[r] > 0$ \\+
        let $A$ be a random set in $\mathrm{F}[r+1]$ \\
        let $a$ be a random element in $E \setminus A$ \\
        replace $A$ with $A \cup \{a\}$ in $\mathrm{F}[r+1]$ \\
        \pr{Superpose!}(\mathrm{F}[r+1], \mathrm{F}[r]) \\

        if $E \in \mathrm{F}[r+1]$ return $(E, \mathrm{F})$ \\

        $p[r] -= 1$ \\-
      $r += 1$

  \end{pseudo}

\end{algorithm}


\subsection{Improving performance}
\label{sec:improving-performance}
When recreating Knuth's table of observed mean values for the randomly generated matroids, some of the latter configurations of $n$ and $(p_1, p_2, \ldots)$ was unworkably slow, presumably due to the naïve implementation of the algorithm. Table~\ref{tab:perf_v1} shows the performance of this first implementation.

\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{random\_kmc\_v1}$.}
  \label{tab:perf_v1}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
        10 & (0, 6, 0)    & 100 & 0.0689663   & 0.0106786 & 147.237 MiB \\
        10 & (0, 5, 1)    & 100 & 0.1197194   & 0.0170734 & 251.144 MiB \\
        10 & (0, 5, 2)    & 100 & 0.0931822   & 0.0144022 & 203.831 MiB \\
        10 & (0, 6, 1)    & 100 & 0.0597314   & 0.0094902 & 132.460 MiB \\
        10 & (0, 4, 2)    & 100 & 0.1924601   & 0.0284532 & 406.131 MiB \\
        10 & (0, 3, 3)    & 100 & 0.3196838   & 0.0463972 & 678.206 MiB \\
        10 & (0, 0, 6)    & 100 & 1.1420602   & 0.1671325 & 2.356 GiB   \\
        10 & (0, 1, 1, 1) & 100 & 2.9283978   & 0.3569357 & 5.250 GiB   \\
        13 & (0, 6, 0)    & 10  & 104.0171128 & 9.9214449 & 161.523 GiB \\
        13 & (0, 6, 2)    & 10  & 11.4881308  & 1.3777947 & 20.888 GiB  \\
        16 & (6, 0, 0)    & 1   & -           & -         & -           \\
      \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table*}

The performance was measured using Julia's \jlinl{@timed}\footnote{\href{https://docs.julialang.org/en/v1/base/base/\#Base.@timed}{https://docs.julialang.org/en/v1/base/base/\#Base.@timed}} macro, which returns the time it takes to execute a function call, how much of that time was spent in garbage collection and the size of the memory allocated. As is evident from the data, larger matroids are computationally quite demanding to compute with the current approach, and the time and space requirements scales exponentially with $n$. Can we do better? As it turns out, we can; after the improvements outlined in this section, we will be able to generate matroids over universes as large as $n=128$ in a manner of seconds and megabytes.

\subsubsection{Representing sets as binary numbers}
The first improvement we will attempt is to represent our families as sets of hexadecimal numbers, instead of sets of sets of numbers. Sets are represented using Julia's native \jlinl{Set} type \footnote{\href{https://docs.julialang.org/en/v1/base/collections/\#Base.Set}{https://docs.julialang.org/en/v1/base/collections/\#Base.Set}}. The Julia implementation at this point can be found in Appendix~\ref{apx:randkmcv2}. \skelpar{Skrive mer om hvordan Set\{Set\{Integer\}\} lagres i minnet og fordelene med å gå over til Set\{Integer\}.}

The idea is to define a family of closed sets of the same rank as \jlinl{Set\{UInt16\}}. Using \jlinl{UInt16} we can support ground sets of size up to 16. Each 16-bit number represents a set in the family. For instance, the set $\{ 2,5,7 \}$ is represented by $$164 = 0\rm{x}00\rm{a}4 = 0\rm{b}0000000010100100 = 2^7+2^5+2^2.$$ At either end we have $\emptyset \equiv 0\rm{x}0000$ and $E \equiv 0\rm{xffff}$ (if $n = 16$). Set operations have equivalent binary operations; intersection corresponds to bitwise AND, union to bitwise OR and the set difference between sets $A$ and $B$ to the bitwise OR of $A$ and the complement of $B$. Subset equality is also simple to implement: $A \subseteq B \iff A \cap B = A.$ 

We can now describe the bitwise versions of the required methods. The bitwise implementation of \pr{Generate-Covers} finds all elements in $E \setminus A$ by finding each value $i$ for which \jlinl{A & 1 << i === 0}, meaning that the set represented by \jlinl{1 << i} is not a subset of A. The bitwise implementation of \pr{Superpose!} is unchanged apart from using the bitwise set operations described above.

\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{random\_kmc\_v2}$.}
  \label{tab:perf_v2}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0] & 100 & 0.0010723 & 0.0001252 & 1.998 MiB \\ 
      10 & [0, 5, 1] & 100 & 0.0017543 & 0.0001431 & 3.074 MiB \\ 
      10 & [0, 5, 2] & 100 & 0.0008836 & 0.0001075 & 2.072 MiB \\ 
      10 & [0, 6, 1] & 100 & 0.0007294 & 6.73e-5 & 1.700 MiB \\ 
      10 & [0, 4, 2] & 100 & 0.0020909 & 0.0001558 & 3.889 MiB \\ 
      10 & [0, 3, 3] & 100 & 0.0024636 & 0.0002139 & 4.530 MiB \\ 
      10 & [0, 0, 6] & 100 & 0.007082 & 0.0004801 & 9.314 MiB \\ 
      10 & [0, 1, 1, 1] & 100 & 0.0132477 & 0.0008307 & 17.806 MiB \\ 
      13 & [0, 6, 0] & 10 & 0.042543 & 0.0014988 & 31.964 MiB \\ 
      13 & [0, 6, 2] & 10 & 0.0183313 & 0.0012176 & 21.062 MiB \\ 
      16 & [0, 6, 0] & 10 & 1.2102877 & 0.0146129 & 450.052 MiB \\ 
      \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table*}

The performance of \mono{random\_kmc\_v2} is shown in Table~\ref{tab:perf_v2}. It is clear that representing closed sets using binary numbers represents a substantial improvement -- we are looking at performance increases of 100x-1000x across the board.


\subsubsection{Sorted superpose}
Can we improve the running time of the algorithm further? It is clear that \pr{Superpose!} takes up a large portion of the compute time. In the worst case, when no enlargements have been made, $F_{r+1}$ is the set of all $r+1$-sized subsets of $E$, $|F_{r+1}| = {\binom{n}{r+1}}$. Comparing each $A,B \in F_{r+1}$ with each $C \in F_r$ in a triply nested for loop requires a whopping $\mathcal{O}({\binom{n}{r+1}}^2{\binom{n}{r}})$ operations. In the worst case, no enlargements are made at all, and we build the free matroid in $\mathcal{O}(2^{3n})$ time.

Observing the step-by-step calls to \pr{Superpose!}, we see that there are a lot of duplicate and unnecessary sets being processed. The duplicate sets stem from \pr{Generate-Covers}, whose current implementation does not take into account that any two sets of rank $r$ will have at least one cover in common. To see this, consider a matroid-under-construction where $A = \{1,2\}$ and $B = \{1,3\}$ are closed sets of rank 2. Currently, \pr{Generate-Covers} will happily generate the cover $C=\{1,2,3\}$ twice, once as the cover of $A$ and subsequently as the cover of $B$. Non-redundant cover generation was a worthwhile improvement and is described below.

After larger closed sets have been added to $\mathrm{F}[r+1]$, \pr{Superpose!} will cause sets to merge, so that only maximal dependent sets remain. Some sets will even simply disappear. In the case where $X=\{1,2\}$ was added by \pr{Generate-Covers}, and the $Y=\{1,2,3\}$ was added manually as an enlargement, the smaller set will be completely subsumed in the bigger set, as $\{1,2\}\cap\{1,2,3\}=\{1,2\}$ and $\{1,2\}\cup\{1,2,3\}=\{1,2,3\}$. In this situation, $X$ will ``eat'' the covers $\{1,3\}$ and $\{2,3\}$ as well. Since the larger sets will absorb so many of the smaller sets (around $\binom{p}{r+1}$, where $p$ is the size of the larger set and $r+1$ is the size of the smallest sets allowed to be added in a given iteration), might it be an idea to perform the superpose operation in descending order based on the size of the sets? This should result in fewer calls to \pr{Superpose!}, as the bigger sets will remove the smaller sets that fully overlap with them in the early iterations, however, the repeated sorting of the sets might negate this performance gain. This was the idea behind \jlinl{random_kmc_v3}, which can be found in Appendix~\ref{apx:randkmcv2}.

Unfortunately, as Table~\ref{tab:perf_v3} shows, this implementation is a few times slower and more space demanding than the previous implementation. This is likely due to the fact that an ordered list is more space inefficient than the hashmap-based \mono{Set}.

\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{random\_kmc\_v3}$.}
  \label{tab:perf_v3}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0] & 100 & 0.0023382 & 0.0001494 & 4.042 MiB \\
      10 & [0, 5, 1] & 100 & 0.001853 & 0.0001433 & 4.383 MiB \\
      10 & [0, 5, 2] & 100 & 0.0017845 & 0.0001341 & 4.043 MiB \\
      10 & [0, 6, 1] & 100 & 0.0015145 & 0.0001117 & 3.397 MiB \\
      10 & [0, 4, 2] & 100 & 0.0030704 & 0.0002125 & 6.385 MiB \\
      10 & [0, 3, 3] & 100 & 0.0037838 & 0.0002514 & 7.018 MiB \\
      10 & [0, 0, 6] & 100 & 0.008903 & 0.000557 & 14.159 MiB \\
      10 & [0, 1, 1, 1] & 100 & 0.0142828 & 0.0008823 & 21.838 MiB \\
      13 & [0, 6, 0] & 10 & 0.0627633 & 0.002094 & 51.492 MiB \\
      13 & [0, 6, 2] & 10 & 0.0106478 & 0.0007704 & 20.774 MiB \\
      16 & [0, 6, 0] & 10 & 0.6070136 & 0.0095656 & 310.183 MiB \\
      \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table*}

\skelpar{Skrive om variansen mellom tilfeldige matroider! @benchmark osv. Histogram}


\subsubsection{Iterative superpose}
So far, we are inserting all covers of $F_r$ into $F_{r+1}$ along with all enlargements, and then running the superpose operation on all of them at once.   Until this point, the superpose operation was performed with a triply nested \mono{for} loop, c Thus we were looking at a whopping  to perform the superpose part of step $r$.



\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{randomized\_kmc\_v4}$.}
  \label{tab:perf_v4}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \skeltabular[15]
    \end{tabular}
  \end{threeparttable}
\end{table*}

\subsubsection{Rank table}
\skelpars[5]

\subsubsection{Non-redundant cover generation and iterative superpose}
\skelpars[7]

\subsection{Finding independent sets and circuits}
In order for the 
\skelpars[15]

\section{Other kinds of matroids}
\skelpars[1]

\subsection{Uniform matroids}
\skelpars[4]

\subsection{Graphic matroids}
\skelpars[6]

\subsection{Vector matroids}
\skelpars[7]