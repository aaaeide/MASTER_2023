\section{Knuth's matroid construction}
\label{sec:kmc}
In the preparatory project to this thesis, delivered to my advisor in the fall of 2022, I implemented Knuth's 1974 algorithm for the random generation of arbitrary matroids via the erection of closed sets \cite{knuth-1975}. With this, I was able to randomly generate matroids of universe sizes $n \leq 12$, but for larger values of $n$ my implementation was unbearably slow. In this section, Knuth's method for random matroid construction will be described, along with the steps I have taken to speed up my initial, na√Øve implementation.

\pr{Knuth-Matroid} (given in Algorithm~\ref{alg:knuth}) accepts the ground set $E$ and a list $\mathrm{X}$ such that $\mathrm{X}[i] \subseteq 2^E$, and produces the rank-$r$ matroid $\mathfrak{M}$ such that $\mbox{rank}(X) = k$ for each $X \in \mathrm{X}[k]$. This is done in a bottom-up manner through $r$ sequential erections starting from the empty rank-0 matroid, $\mathfrak{M}^{(0)}$, each iteration $i$ producing the erection $\mathfrak{M}^{(i+1)}$ from $\mathfrak{M}^{(i)}$ and $\mathrm{X}[i]$. The algorithm outputs the tuple $(E, \mathrm{F})$, where $\mathrm{F} = [F_0, \ldots, F_r]$, $r$ being the final rank of $\mathfrak{M}$ and $F_i$ the family of closed sets of rank $i$. In the paper, Knuth shows that $\bigcup_{i=0}^r \mathrm{F}[r] = \mathcal{F}$, where $\mathcal{F}$ is the set of closed sets of a matroid, and so the algorithm produces a valid matroid represented by its closed sets.

\begin{algorithm}[float*=ht!]{\pr{Knuth-Matroid}(E, \mathrm{X})}{knuth}

  \textbf{Input:}     \tab The ground set of elements $E$, and a list of enlargements $\mathrm{X}$.

  \textbf{Output:}    \tab The list of closed sets of the resulting matroid grouped by rank, \\
  \mbox{}\tab $\mathrm{F} = [F_0, \ldots, F_r]$, where $F_i$ is the set of closed sets of rank $i$.

  \begin{pseudo}[kw, label=\small\arabic*, indent-mark, line-height=1.2]
    $r = 0, \mathrm{F} = [\{ \emptyset \}]$ \\
    while \cn{true}  \\+
    $\pr{Push!}(\mathrm{F}, \pr{Generate-Covers}(\mathrm{F}, r, E))$ \\
    $\mathrm{F}[r+1] = \mathrm{F}[r+1] \cup \mathrm{X}[r+1]$ \\
    \pr{Superpose!}(\mathrm{F}[r+1], \mathrm{F}[r]) \\

    if $E \not \in F[r+1]$ \\+
    $r \leftarrow r+1$ \\-
    else \\+
    return $(E, \mathrm{F})$

  \end{pseudo}

\end{algorithm}

To understand the procedure, let us investigate what Algorithm~\ref{alg:knuth} does at iteration $1<i<r$, where $r$ is the final rank $\mathfrak{M}$, the matroid under construction. At iteration $i$, we produce a rank-$(i+1)$ erection $\mathfrak{M}^{(i+1)}$ of $\mathfrak{M}^{(i)}$, which is represented by its closed sets $\mathrm{F} = [F_0, F_1, ..., F_i]$, where $F_i$ is the set of closed sets of rank $i$. We want to produce the set $F_{i+1}$ of rank-$r$ closed sets of an erection of $\mathfrak{M}^{(i)}$ such that each $X \in \mathrm{X}[i]$ is contained in some rank-$r$ closed set. First we find the ``covers'' of each closed set in $F_i$. The covers of a closed set $A$ of rank $r$ are the sets obtained by adding one more element from $E$ to $A$. The covers are generated with \pr{Generate-Covers}(\mathrm{F}, r, E).

\begin{tcolorbox}[pseudo/boxruled]
  \begin{pseudo}*
    \hd{Generate-Covers}(\mathrm{F}, r, E) \\
    return $\{ A \cup \{a\} : A \in \mathrm{F}[r], a \in E \setminus A \}$
  \end{pseudo}
\end{tcolorbox}

Given no enlargements ($\mathrm{X}[i] = \emptyset$), the resulting matroid $\mathfrak{M}^{(i+1)}$ is the \textit{free erection} of $\mathfrak{M}^{(i)}$, and there are no essential closed sets in $F_{i+1}$. Arbitrary matroids can be generated by supplying different lists $\mathrm{X}$. When enlarging, the sets in $\mathrm{X}[r+1]$ are simply added to $\mathrm{F}[r+1]$, before \pr{Superpose!} is run to ensure that the newly enlarged family of closed sets of rank $r+1$ is valid (ie. in accordance with the closed set axioms given in Section~\ref{sec:matroid-theory}). If $F_{r+1}$ contains two sets $A,B$ whose intersection $A \cap B \not \subseteq C$ for any $C \in F_{r}$ (in other words, their intersection is not a closed set), replace $A,B$ with $A \cup B$. Repeat until no two sets exist in $F_{r+1}$ whose intersection is not contained within some set $C \in F_{r}$.


\begin{tcolorbox}[pseudo/boxruled, float*=ht!]
  \begin{pseudo}[kw, indent-mark]*
    \hd{Superpose!}({F_{r+1},F_r}) \\
    for $A \in F_{r+1}$ \\+
    for $B \in F_{r+1}$ \\+
    \id{flag} $\leftarrow$ \cn{true} \\
    for $C \in F_r$ \\+
    if $A \cap B \subseteq C$ \\+
    \id{flag} $\leftarrow$ \cn{false} \\--
    \\
    if \id{flag} = \cn{true} \\+
    $F_{r+1} \leftarrow F_{r+1} \setminus \{A, B \}$ \\
    $F_{r+1} \leftarrow F_{r+1} \cup \{A \cup B \}$
  \end{pseudo}
\end{tcolorbox}


\subsection{Randomized KMC}
In the randomized version of \pr{Knuth-Matroid}, we generate matroids by applying a supplied number of random coarsening steps, instead of enlarging with supplied sets. This is done by applying \pr{Superpose!} immediately after adding the covers, then choosing a random member $A$ of $\mathrm{F}[r+1]$ and a random element $a \in E \setminus A$, replacing $A$ with $A \cup \{a\}$ and finally reapplying \pr{Superpose!}. The parameter $p = (p_1, p_2, \ldots)$ gives the number of such coarsening steps to be applied at each iteration of the algorithm.

The pseudocode descriptions of Knuth's matroid construction hews closely to the initial Julia implementation. It should already be clear that this brute force approach leads to poor performance---for instance, the \pr{Superpose!} method uses a triply nested for loop, which seems like a candidate for significant improvement. Section~\ref{sec:improving-performance} describes the engineering work done to create a more performant implementation.

\begin{algorithm}[float*=ht!]{\pr{Randomized-Knuth-Matroid}(E, p)}{rkmc}

  \textbf{Input:}     \tab The ground set of elements $E$, and a list $p = [p_1, p_2, ...]$, where \\
  \mbox{}\tab $p_r$ is the number of coarsening steps to apply at rank $r$ in the \\
  \mbox{}\tab construction.

  \textbf{Output:}    \tab The list of closed sets of the resulting matroid grouped by rank, \\
  \mbox{}\tab $\mathrm{F} = [F_0, \ldots, F_r]$, where $F_i$ is the set of closed sets of rank $i$.

  \begin{pseudo}[label=\small\arabic*, indent-mark, line-height=1.2]
    $r = 0, \mathrm{F} = [\{ \emptyset \}]$ \\
    \kw{while} \cn{true}  \\+
      $\pr{Push!}(\mathrm{F}, \pr{Generate-Covers}(\mathrm{F}, r, E))$ \\
      \pr{Superpose!}(\mathrm{F}[r+1], \mathrm{F}[r]) \\
      
      \kw{if} $E \in \mathrm{F}[r+1]$ \kw{return} $(E, \mathrm{F})$ \\
      
      \kw{while} $p[r] > 0$ \\+
        $A \leftarrow$ a random set in $\mathrm{F}[r+1]$ \\
        $a \leftarrow$ a random element in $E \setminus A$ \\
        \kw{replace} $A$ with $A \cup \{a\}$ in $\mathrm{F}[r+1]$ \\
        \pr{Superpose!}(\mathrm{F}[r+1], \mathrm{F}[r]) \\

        \kw{if} $E \in \mathrm{F}[r+1]$ \kw{return} $(E, \mathrm{F})$ \\

        $p[r] = p[r] - 1$ \\-
      $r = r + 1$

  \end{pseudo}

\end{algorithm}


\subsection{Improving performance}
\label{sec:improving-performance}
In the preparatory project to this thesis, I was able to recreate Knuth's table of observed mean values for the randomly generated matroids, but I was dismayed to find that my implementation was unable to handle matroids whose ground sets were even just a few elements larger. Considering that Knuth was able to run his experiments on the hardware available to him in the 1970s, I concluded that my implementation had room for improvement. Table~\ref{tab:perf_v1} shows the performance of my first implementation.

\begin{table*}[ht!]
  \centering
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
        10 & (0, 6, 0)    & 100 & 0.0689663   & 0.0106786 & 147.237 MiB \\
        10 & (0, 5, 1)    & 100 & 0.1197194   & 0.0170734 & 251.144 MiB \\
        10 & (0, 5, 2)    & 100 & 0.0931822   & 0.0144022 & 203.831 MiB \\
        10 & (0, 6, 1)    & 100 & 0.0597314   & 0.0094902 & 132.460 MiB \\
        10 & (0, 4, 2)    & 100 & 0.1924601   & 0.0284532 & 406.131 MiB \\
        10 & (0, 3, 3)    & 100 & 0.3196838   & 0.0463972 & 678.206 MiB \\
        10 & (0, 0, 6)    & 100 & 1.1420602   & 0.1671325 & 2.356 GiB   \\
        10 & (0, 1, 1, 1) & 100 & 2.9283978   & 0.3569357 & 5.250 GiB   \\
        13 & (0, 6, 0)    & 10  & 104.0171128 & 9.9214449 & 161.523 GiB \\
        13 & (0, 6, 2)    & 10  & 11.4881308  & 1.3777947 & 20.888 GiB  \\
        16 & (6, 0, 0)    & 1   & -           & -         & -           \\
      \bottomrule
    \end{tabular}
  \end{threeparttable}
  \caption{Performance of $\texttt{random\_kmc\_v1}$.}
  \label{tab:perf_v1}
\end{table*}

The performance was measured using Julia's \jlinl{@timed}\footnote{\href{https://docs.julialang.org/en/v1/base/base/\#Base.@timed}{https://docs.julialang.org/en/v1/base/base/\#Base.@timed}} macro, which returns the time it takes to execute a function call, how much of that time was spent in garbage collection and the number of bytes allocated. The experiments was run on a 2021 MacBook Pro with the Apple M1 chip and 16GB RAM. As is evident from the data, larger matroids are computationally quite demanding to compute with this current approach, and the time and space requirements scales exponentially with $n$.

\subsubsection{Representing sets as binary numbers}
The first improvement we will attempt is to represent our closed sets using one of Julia's \jlinl{Integer} types of bit width at least $n$, instead of as a \jlinl{Set}\footnote{\href{https://docs.julialang.org/en/v1/base/collections/\#Base.Set}{https://docs.julialang.org/en/v1/base/collections/\#Base.Set}} of elements of $E$. Appendix~\ref{apx:code} contains all the code referenced in this chapter; the Julia implementation at this point can be found in \ref{apx:randkmcv2}. 

The idea is to define a family of closed sets of the same rank as \jlinl{Set\{UInt16\}}. Using \jlinl{UInt16} we can support ground sets of size up to 16. Each 16-bit number represents a set in the family. For example, the set $\{ 2,5,7 \}$ is represented by $$164 = 0\rm{x}00\rm{a}4 = 0\rm{b}0000000010100100 = 2^7+2^5+2^2.$$ At either end we have $\emptyset \equiv 0\rm{x}0000$ and $E \equiv 0\rm{xffff}$ (if $n = 16$). The elementary set operations we will need have simple implementations using bitwise operations.

\begin{table}[!ht]
  % \caption{Set operations and their equivalent bitwise operations}
  \centering
  \begin{tabular}{|l|l|}
  \hline
      Set operation & Bitwise operation \\\hline
      $A \cap B$      & $A$ AND $B$ \\\hline
      $A \cup B$      & $A$ OR $B$ \\\hline
      $A \setminus B$ & $A$ AND NOT $B$ \\\hline
      $A \subseteq B$ & $A$ AND $B$ = $A$ \\\hline
  \end{tabular}
\end{table}

We can now describe the bitwise versions of the required methods. The bitwise implementation of \pr{Generate-Covers} finds all elements in $E \setminus A$ by finding each value $0\leq i< n$ for which \jlinl{A & 1 << i === 0}, meaning that the set represented by \jlinl{1 << i} is not a subset of A. The bitwise implementation of \pr{Superpose!} is unchanged apart from using the bitwise set operations described above.

\begin{table*}[ht!]
  \centering
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0] & 100 & 0.0010723 & 0.0001252 & 1.998 MiB \\ 
      10 & [0, 5, 1] & 100 & 0.0017543 & 0.0001431 & 3.074 MiB \\ 
      10 & [0, 5, 2] & 100 & 0.0008836 & 0.0001075 & 2.072 MiB \\ 
      10 & [0, 6, 1] & 100 & 0.0007294 & 6.73e-5 & 1.700 MiB \\ 
      10 & [0, 4, 2] & 100 & 0.0020909 & 0.0001558 & 3.889 MiB \\ 
      10 & [0, 3, 3] & 100 & 0.0024636 & 0.0002139 & 4.530 MiB \\ 
      10 & [0, 0, 6] & 100 & 0.007082 & 0.0004801 & 9.314 MiB \\ 
      10 & [0, 1, 1, 1] & 100 & 0.0132477 & 0.0008307 & 17.806 MiB \\ 
      13 & [0, 6, 0] & 10 & 0.042543 & 0.0014988 & 31.964 MiB \\ 
      13 & [0, 6, 2] & 10 & 0.0183313 & 0.0012176 & 21.062 MiB \\ 
      16 & [0, 6, 0] & 10 & 1.2102877 & 0.0146129 & 450.052 MiB \\ 
      \bottomrule
    \end{tabular}
  \end{threeparttable}
  \caption{Performance of $\texttt{random\_kmc\_v2}$.}
  \label{tab:perf_v2}
\end{table*}

The performance of \mono{random\_kmc\_v2} is shown in Table~\ref{tab:perf_v2}. It is clear that representing closed sets using binary numbers represents a substantial improvement -- we are looking at performance increases of 100x-1000x across the board.


\subsubsection{Sorted superpose}
Can we improve the running time of our implementation further? It is clear that \pr{Superpose!} takes up a large portion of the compute time. In the worst case, when no enlargements have been made, $F_{r+1}$ is the set of all $r+1$-sized subsets of $E$, $|F_{r+1}| = {\binom{n}{r+1}}$. Comparing each $A,B \in F_{r+1}$ with each $C \in F_r$ in a triply nested for loop requires $\mathcal{O}({\binom{n}{r+1}}^2{\binom{n}{r}})$ operations. In the worst case, no enlargements are made at all, and we build the free matroid in $\mathcal{O}(2^{3n})$ time (considering only the superpose step).

After larger closed sets have been added to $\mathrm{F}[r+1]$, \pr{Superpose!} will cause sets to merge, so that only maximal dependent sets remain. Some sets will even simply disappear. In the case where $X=\{1,2\}$ was added by \pr{Generate-Covers}, and the $Y=\{1,2,3\}$ was added manually as an enlargement, the smaller set will be fully subsumed in the bigger set, as $\{1,2\}\cap\{1,2,3\}=\{1,2\}$ (which is not a subset of any set in $\mathrm{F}[r]$) and $\{1,2\}\cup\{1,2,3\}=\{1,2,3\}$. In this situation, $Y$ would ``eat'' the covers $\{1,3\}$ and $\{2,3\}$ as well. This fact is reflected in the performance data -- compare the memory allocation differences between the 10-element matroid with $p=[0,0,6]$ and the one with $p=[0,6,0]$ in any of the performance tables in this section. Making enlargements at earlier ranks result in smaller matroids as more sets get absorbed.

\begin{jllisting}
function sorted_bitwise_superpose!(F, F_prev)
  As = sort!(collect(F), by = s -> length(bits_to_set(s)))
  while length(As) !== 0
    A = popfirst!(As)

    for B in setdiff(F, A)
      if should_merge(A, B, F_prev)
        insert!(As, 1, A | B)
        setdiff!(F, [A, B])
        push!(F, A | B)
        break
      end
    end
  end

  return F
end
\end{jllisting}

Since the larger sets will absorb so many of the smaller sets (around $\binom{p}{r+1}$, where $p$ is the size of the larger set and $r+1$ is the size of the smallest sets allowed to be added in a given iteration), might it be an idea to perform the superpose operation in descending order based on the size of the sets? This should result in fewer calls to \pr{Superpose!}, as the bigger sets will remove the smaller sets that fully overlap with them in the early iterations, however, the repeated sorting of the sets might negate this performance gain. This is the idea behind \jlinl{sorted_bitwise_superpose!}, which was used in \jlinl{random_kmc_v3}. The full code can be found in Appendix~\ref{apx:randkmcv2}.

Unfortunately, as Table~\ref{tab:perf_v3} shows, this implementation is a few times slower and more space demanding than the previous implementation. This is might be due to the fact that an ordered list is more space inefficient than the hashmap-based \jlinl{Set}.

\begin{table*}[ht!]
  \centering
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0] & 100 & 0.0023382 & 0.0001494 & 4.042 MiB \\
      10 & [0, 5, 1] & 100 & 0.001853 & 0.0001433 & 4.383 MiB \\
      10 & [0, 5, 2] & 100 & 0.0017845 & 0.0001341 & 4.043 MiB \\
      10 & [0, 6, 1] & 100 & 0.0015145 & 0.0001117 & 3.397 MiB \\
      10 & [0, 4, 2] & 100 & 0.0030704 & 0.0002125 & 6.385 MiB \\
      10 & [0, 3, 3] & 100 & 0.0037838 & 0.0002514 & 7.018 MiB \\
      10 & [0, 0, 6] & 100 & 0.008903 & 0.000557 & 14.159 MiB \\
      10 & [0, 1, 1, 1] & 100 & 0.0142828 & 0.0008823 & 21.838 MiB \\
      13 & [0, 6, 0] & 10 & 0.0627633 & 0.002094 & 51.492 MiB \\
      13 & [0, 6, 2] & 10 & 0.0106478 & 0.0007704 & 20.774 MiB \\
      16 & [0, 6, 0] & 10 & 0.6070136 & 0.0095656 & 310.183 MiB \\
      \bottomrule
    \end{tabular}
  \end{threeparttable}
  \caption{Performance of $\texttt{random\_kmc\_v3}$.}
  \label{tab:perf_v3}
\end{table*}


\subsubsection{Iterative superpose}
The worst-case $\mathcal{O}({\binom{n}{r+1}}^2{\binom{n}{r}})$ runtime of \pr{Superpose!} at step $r$ is due to the fact that it takes in $\mathrm{F}$ after all covers and enlargements have been indiscriminately added to $\mathrm{F}[r+1]$ and then loops through to perform the superposition. Might there be something to gain by inserting new closed sets into the current family one at a time, and superposing on the fly?

\begin{jllisting}
  # Superpose (random_kmc_v4)
  push!(F, Set()) # Add F[r+1].
  while length(to_insert) > 0
    A = pop!(to_insert)
    push!(F[r+1], A)

    for B in setdiff(F[r+1], A)
      if should_merge(A, B, F[r])
        push!(to_insert, A | B)
        setdiff!(F[r+1], [A, B])
        push!(F[r+1], A | B)
      end
    end
  end
\end{jllisting}

In \jlinl{random_kmc_v4}, the full code of which can be found in Appendix~\ref{apx:randkmcv4}, the covers and enlargements are not added directly to $\mathrm{F}[r+1]$, but to a temporary array \jlinl{to_insert}. Each set $A$ is then popped from \jlinl{to_insert} one at a time, added to $\mathrm{F}[r+1]$ and compared with the other sets $B \in \mathrm{F}[r+1] \setminus \{A\}$ and $C \in \mathrm{F}[r]$ in the usual \pr{Superpose!} manner. This results in fewer comparisons, as each set is only compared with the sets added before it; the first set is compared with no other sets, the second set with one other and the sets in $\mathrm{F}[r]$, and so on. The number of such comparisons is therefore given by the triangular number $T_{\binom{n}{r+1}}$, and so we should have roughly halved the runtime at step $r$. It is worth noting that this implementation of \pr{Superpose!} uses a subroutine \jlinl{should_merge} that returns early when it finds one set $C \in \mathrm{F}[r]$ such that $C \supseteq A \cap B$, so in practice it usually does not require $\binom{n}{r}$ comparisons in the innermost loop.

Table~\ref{tab:perf_v4} shows that the iterative superpose was a meaningful improvement. For most input configurations, it is a few times faster and a few times less space demanding than \jlinl{random_kmc_v2}.


\begin{table*}[ht!]
  \centering
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0]    & 100 & 0.0014585  & 3.94e-5   & 724.635 KiB \\ 
      10 & [0, 5, 1]    & 100 & 0.0007192  & 9.39e-5   & 659.729 KiB \\ 
      10 & [0, 5, 2]    & 100 & 0.0005943  & 3.53e-5   & 617.668 KiB \\ 
      10 & [0, 6, 1]    & 100 & 0.0003502  & 2.88e-5   & 408.666 KiB \\ 
      10 & [0, 4, 2]    & 100 & 0.001013   & 5.36e-5   & 887.618 KiB \\ 
      10 & [0, 3, 3]    & 100 & 0.0011847  & 5.03e-5   & 1.003 MiB   \\ 
      10 & [0, 0, 6]    & 100 & 0.0015756  & 9.7e-5    & 1.066 MiB   \\ 
      10 & [0, 1, 1, 1] & 100 & 0.0046692  & 0.0001385 & 2.455 MiB   \\ 
      13 & [0, 6, 0]    & 10  & 0.0118201  & 0.0005486 & 6.289 MiB   \\ 
      13 & [0, 6, 2]    & 10  & 0.0075668  & 0.0002458 & 4.666 MiB   \\ 
      16 & [0, 6, 0]    & 10  & 0.2819294  & 0.0040792 & 81.317 MiB  \\ 
      16 & [0, 6, 1]    & 10  & 0.8268207  & 0.0070206 & 154.451 MiB \\ 
      16 & [0, 0, 6]    & 10  & 95.1959596 & 0.0290183 & 553.597 MiB \\ 
      \bottomrule
    \end{tabular}
  \end{threeparttable}
  \caption{Performance of $\texttt{random\_kmc\_v4}$.}
  \label{tab:perf_v4}
\end{table*}

\subsubsection{Rank table}
While \pr{Superpose!} is getting more efficient, it is still performing the same comparisons over and over again. Let's consider what we are really trying to achieve with this function, to see if we can't find a smarter way to go about it.

After adding the closed sets for a rank, \pr{Superpose!} is run to maintain the closed set properties of the matroid (given in Section~\ref{sec:matroid-theory}). These are maintained by ensuring that, for any two newly added sets $A,B \in \mathrm{F}[r+1]$, there exists $C \in \mathrm{F}[r]$ such that $A \cap B \subseteq C$. Up to this point, this has been done by checking if the intersection of each such $A,B$ is contained in a set $C$ of rank $r$. We remember that one of the properties of the closed sets of a matroid is that the intersection of two closed sets is itself a closed set. Therefore, we do not need to find a closed set $C$ of rank $r$ that \textit{contains} $A \cap B$, since if $A$ and $B$ are indeed closed sets, their intersection will be \textit{equal} to some closed set $C$ of any rank $\leq r$. This insight leads us to the next improvement: if we keep track of all added closed sets in a rank table, then we can memoize \pr{Superpose!} and replace the innermost loop with a constant time dictionary lookup.

\begin{jllisting}
  # The rank table maps from the representation of a set to its assigned rank.
  rank = Dict{T, UInt8}(0=>0)
  
  [...]
  
  # Superpose.
  push!(F, Set()) # Add F[r+1].
  while length(to_insert) > 0
    A = pop!(to_insert)
    push!(F[r+1], A)
    rank[A] = r
  
    
    for B in setdiff(F[r+1], A)
      if !haskey(rank, A&B) || rank[A&B] >= r
        # Update insert queue.
        push!(to_insert, A | B)
    
        # Update F[r+1].
        setdiff!(F[r+1], [A, B])
        push!(F[r+1], A | B)
    
        # Update rank table.
        rank[A|B] = r
        break
      end
    end
  end
\end{jllisting}
\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{random\_kmc\_v5}$.}
  \label{tab:perf_v5}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0] & 100 & 0.0001335 & 0.0 & 138.966 KiB \\
      10 & [0, 5, 1] & 100 & 0.0001436 & 0.0 & 158.691 KiB \\
      10 & [0, 5, 2] & 100 & 0.0001928 & 0.0 & 167.487 KiB \\
      10 & [0, 6, 1] & 100 & 0.0002204 & 0.0 & 148.812 KiB \\
      10 & [0, 4, 2] & 100 & 0.0001578 & 0.0 & 173.455 KiB \\
      10 & [0, 3, 3] & 100 & 0.0001743 & 0.0 & 202.566 KiB \\
      10 & [0, 0, 6] & 100 & 0.0003433 & 0.0 & 431.089 KiB \\
      10 & [0, 1, 1, 1] & 100 & 0.0004987 & 0.0 & 439.511 KiB \\
      13 & [0, 6, 0] & 100 & 0.0004776 & 0.0 & 422.431 KiB \\
      13 & [0, 6, 2] & 100 & 0.0003469 & 0.0 & 441.621 KiB \\
      16 & [0, 6, 0] & 100 & 0.0009073 & 0.0 & 1010.452 KiB \\
      16 & [0, 6, 1] & 100 & 0.0007939 & 0.0 & 997.022 KiB \\
      16 & [0, 0, 6] & 100 & 0.0066951 & 0.0 & 8.564 MiB \\
      20 & [0, 6, 0] & 100 & 0.0030797 & 0.0 & 4.042 MiB  \\
      20 & [0, 6, 2] & 10 & 0.0022849 & 0.0 & 4.547 MiB  \\
      32 & [0, 6, 2, 1] & 10 & 0.0269912 & 0.0 & 63.082 MiB  \\
      \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table*}
The full code for \jlinl{random_kmc_v5} can be found in Appendix~\ref{apx:randkmcv5}. Table~\ref{tab:perf_v5} shows that implementing a rank table was an extremely significant improvement. For smaller matroids, it is around 5-10x faster, however it is for larger matroids that it truly outshines its predecessors -- \jlinl{random_kmc_v5} is a whopping 13~000 times faster than \jlinl{random_kmc_v4} with $n=16, p=[0,0,6]$ as input.


\subsubsection{Non-redundant cover generation}
Up to this point, our cover generation routine has not taken into account that any two sets of rank $r$ will have at least one cover in common. To see this, consider a matroid-under-construction with $n=10$ where $A = \{1,2\}$ and $B = \{1,3\}$ are closed sets of rank 2. Currently, \pr{Generate-Covers} will happily generate the cover $C=\{1,2,3\}$ twice, once as the cover of $A$ and subsequently as the cover of $B$. Throughout this analysis, we will assume the worst case scenario of no enlargements, as any enlargements will strictly lower the number of sets in play at a given rank. In this case, $|\mathrm{F}[r]| = \binom{n}{r}$, and for each closed set $A$ of rank $r$ we are generating $|E\setminus A| = (n-r)$ covers, giving us a total of $\binom{n}{r}(n-r)$ covers generated at each rank $r$, including the duplicates. With no enlargements, we know that there are $\binom{n}{r+1}$ covers, and

$$\begin{aligned}
  (n-r)\binom{n}{r} &= \frac{n!(n-r)}{r!(n-r)!} \\
                    &= \frac{n!}{r!(n-r-1)!} \\
                    &= (r+1)\frac{n!}{(r+1)!(n-r-1)!} \\
                    &= (r+1)\binom{n}{r+1}. \\
\end{aligned}$$
For each step $r$, we are generating $r+1$ times as many covers as we need to. Over the course of all steps $0\leq r\leq n$, we are generating $$\sum_{r=0}^n (r+1) = \sum_{r=1}^{n+1}r = T_{n+1}$$ times the actual number of covers, where $T_{n+1}=\frac{(n+1)(n+2)}{2}$ is the triangular number. In other words, if we find a way to generate each cover only once, we will have shaved off an $n^2$ factor from the asymptotic complexity of our implementation.

When generating covers, \jlinl{random_kmc_v6} improves upon the brute force cover generation described above by only adding the covers 
$$\Bigl\{ A \cup \{ a \} : A \in \mathrm{F}[r], a \in E \setminus A, a \notin \bigcup \bigl\{ B : B \in \mathrm{F}[r+1], A \subseteq B \bigr\} \Bigr\}.$$
In other words, we find the covers of $A$, that is, the sets obtained by adding one more element $a$ from $E$ to $A$, but we do not include any $a$ that is to be found in another, already added, cover $B$ that contains $A$. This solves the problem described above; the cover $\{1,2,3\} = B \cup \{ 2 \}$ will not be generated, as $2 \in C$ and $B \subseteq C$. This is implemented in the following manner:

\begin{jllisting}
  # Generate minimal closed sets for rank r+1 (random_kmc_v6)
  for y in F[r] # y is a closed set of rank r.
    t = E - y # The set of elements not in y.
    # Find all sets in F[r+1] that already contain y and remove excess elements from t.
    for x in F[r+1]
      if (x & y == y) t &= ~x end
      if t == 0 break end
    end
    # Insert y ‚à™ a for all a ‚àà t.
    while t > 0
      x = y|(t&-t)
      add_set!(x, F, r, rank)
      t &= ~x
    end
  end
\end{jllisting}
We have extracted the iterative superpose logic described above into its own function to allow it to be performed on a cover-per-cover basis:
\begin{jllisting}
function add_set!(x, F, r, rank)
  if x in F[r+1] return end
  for y in F[r+1]
    if haskey(rank, x&y) && rank[x&y]<r
    continue
    end
    
    # x ‚à© y has rank > r, replace with x ‚à™ y.
    setdiff!(F[r+1], y)
    return add_set!(x|y, F, r, rank)
  end
  
  push!(F[r+1], x)
  rank[x] = r
end
\end{jllisting}
As such, $\mathrm{F}[r+1]$ is empty when the first cover $y \in \mathrm{F}$ is generated, and all covers $\{y \cup \{a\} : a \in E \setminus y\}$ are added. For later sets $y$, we are comparing with the previously added covers, and dropping any element to be found in a cover $x$ that fully includes $y$. This way, we avoid re-generating the cover $x$.


The full code for \jlinl{random_kmc_v6} can be found in Appendix~\ref{apx:randkmcv6}.

\begin{table*}[ht!]
  \centering
  \caption{Performance of $\texttt{random\_kmc\_v6}$.}
  \label{tab:perf_v6}
  \begin{threeparttable}
    \begin{tabular}{llllllllll}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & Time  & GC Time & Bytes allocated \\
      \midrule
      10 & [0, 6, 0] & 100 & 0.000157 & 0.0 & 11.306 KiB \\
      10 & [0, 5, 1] & 100 & 0.0001427 & 0.0 & 12.257 KiB \\
      10 & [0, 5, 2] & 100 & 0.000121 & 0.0 & 11.568 KiB \\
      10 & [0, 6, 1] & 100 & 8.61e-5 & 0.0 & 10.447 KiB \\
      10 & [0, 4, 2] & 100 & 0.0001237 & 0.0 & 13.597 KiB \\
      10 & [0, 3, 3] & 100 & 0.0001233 & 0.0 & 14.029 KiB \\
      10 & [0, 0, 6] & 100 & 0.0002856 & 0.0 & 15.414 KiB \\
      10 & [0, 1, 1, 1] & 100 & 0.0001942 & 0.0 & 14.446 KiB \\
      13 & [0, 6, 0] & 100 & 0.0004483 & 0.0 & 19.117 KiB \\
      13 & [0, 6, 2] & 100 & 0.0004541 & 0.0 & 18.957 KiB \\
      16 & [0, 6, 0] & 10 & 0.0014919 & 0.0 & 34.531 KiB \\
      16 & [0, 6, 1] & 10 & 0.0014731 & 0.0 & 36.016 KiB \\
      16 & [0, 0, 6] & 10 & 0.0168858 & 0.0 & 127.652 KiB \\
      20 & [0, 6, 0] & 10 & 0.0061574 & 0.0 & 81.573 KiB \\
      20 & [0, 6, 2] & 10 & 0.0059717 & 0.0 & 82.323 KiB \\
      32 & [0, 6, 2, 1] & 10 & 0.1599507 & 0.0 & 279.531 KiB \\
      63 & [0, 6, 4, 2, 1] & 1 & 11.138914 & 0.0 & 4.912 MiB \\
      64 & [0, 6, 4, 4, 2, 1] & 1 & 12.508729 & 0.0 & 4.912 MiB \\
      128 & [0, 6, 6, 4, 4, 2, 1] & 1 & 1232.8570 & 0.0114583 & 102.159 MiB \\
      \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table*}
\skelpar

\subsection{Finding the properties of erected matroids}
The fact that \pr{Knuth-Matroid} fully enumerates all closed sets of the matroid as it erects it rank by rank begs the question: can we build the other families of sets for the matroids alongside the closed sets? In this section, I will first describe an extension of \pr{Knuth-Matroid} that also fully enumerates $\mathcal{I}$ and $\mathcal{C}$ for $\mathfrak{M}$ when $n$ is small enough. Sadly, this approach does not scale well for larger values of $n$, as the size of these sets undergoes a combinatorial explosion as $n$ increases. 

\subsubsection{Up-front enumeration of circuits and independent sets for smaller matroids}
In his 1974 paper~\cite{knuth-1975}, Knuth includes an ALGOL W~\cite{wirth-1966} implementation that also enumerates all circuits and independent sets for the generated matroid. A later implementation in C called ERECTION.W can be found at his home page~\cite{knuth-2003}. \jlinl{random_erect} is an extension of \jlinl{random_kmc_v6} that finds $\mathcal{I}$ and $\mathcal{C}$ by pre-populating the rank table with all subsets of $E$. The full source code for \jlinl{random_erect} can be found in Appendix~XXX.

\begin{jllisting}
  # Populate rank table with 100+cardinality for all subsets of E.
  k=1; rank[0]=100;
  while (k<=mask)
    for i in 0:k-1 rank[k+i] = rank[i]+1 end
    k=k+k;
  end
\end{jllisting}

Covers are generated and sets inserted in the same manner as in\linebreak\jlinl{random_kmc_v6}. After all covers and enlargements have been inserted and superposed (meaning $\mathrm{F}[r+1]$ contains the closed sets of rank $r+1$), a new operation, \jlinl{mark_independent_subsets!} is called on each closed set.

\skelpar

\subsubsection{Determining matroid properties post-erection}
In a 1989 paper, Greene introduces the concept of \textit{descriptive sufficiency}. A subcollection of closed sets of a matroid is descriptively sufficient if it can be used to identify the fundamental properties of the matroid using certain easily applied conditions. The collection of all closed sets of a matroid is one descriptively sufficient such collection~\cite{greene-1991}. 

\paragraph{Rank function.} With every closed set of a matroid in hand, finding the rank of a set $S$ is simply a matter of finding the closed set $F$ of least rank such that $S\subseteq F$.

\begin{figure}[ht!]
\begin{jllisting}
function rank(M::ClosedSetsMatroid, S::Integer)
  for (r, Fr) in enumerate(M.F), B ‚àà Fr
      if S&B == S return r-1 end
  end
end
\end{jllisting}
\end{figure}

\paragraph{Indepence oracle.} To check if a set $S$ is independent, we compare it with the closed sets of rank $|S|-1$. If $S$ is indeed independent, it cannot be a subset of a closed set of lower rank, so if we find one such set we return false. Otherwise, $S$ is independent.

\begin{figure}[ht!]
\begin{jllisting}
function is_indep(M::ClosedSetsMatroid, S::Integer)
  t = Base.count_ones(S)

  if t > length(M.F) return false end

  for F in M.F[t]
    if S&F==S return false end
  end

  return true
end
\end{jllisting}
\end{figure}

\paragraph{Closure function.} Determining the closure of a set $S$ in this case is the exact same procedure as finding the rank: the closed set $F$ of least rank such that $S\subseteq F$ is the closure of $S$.
\begin{figure}[ht!]
\begin{jllisting}
function closure(M::ClosedSetsMatroid, S::Integer)
  for Fr in M.F, B ‚àà Fr
      if S&B == S return B end
  end
end
\end{jllisting}
\end{figure}

\paragraph{Circuit oracle.} Greene also gives a procedure for determining whether a set is a circuit in a matroid described by its family of closed sets~\cite{greene-1991}.

\begin{figure}[ht!]
\begin{jllisting}
function is_circuit(M::ClosedSetsMatroid, S::Integer)
  t = Base.count_ones(S)

  for F in M.F[t] # (C.1) S ‚äÜ F for some F ‚àà F_{t-1}.
    if S&F==S @goto C2 end
  end
  return false

  @label C2
  for F in M.F[t-1] # (C.2) |S ‚à© F| ‚â§ r(F) for all F ‚àà F_{t-2}.
    if Base.count_ones(S&F) > t-2 return false end
  end

  return true
end
\end{jllisting}
\end{figure}

% \begin{jllisting}
% """
%     function minimal_spanning_subsets(M::ClosedSetsMatroid, A::Integer)

% A modification of Algorithm 3.1 from Greene (1989) that finds all minimal spanning subsets of A ‚äÜ E, given a matroid M = (E, F). If A = E, this finds the bases of M.
% """
% minimal_spanning_subsets(M::ClosedSetsMatroid, A::Integer) = _mss_all(M, 0, A)

% function _mss_all(M::ClosedSetsMatroid, j::Integer, AÃÑ::Integer)
%   B = [AÃÑ&F for F in M.F[j+1] if Base.count_ones(AÃÑ&F) > j]

%   while length(B) == 0
%     if j >= Base.count_ones(AÃÑ)-1 return AÃÑ end
    
%     j += 1
%     B = [AÃÑ&F for F in M.F[j+1] if Base.count_ones(AÃÑ&F) > j]
%   end

%   bases = Set()
%   t = reduce(|, B)
%   while t > 0
%     x = t&-t
%     bases = bases ‚à™ _mss_all(M, j, AÃÑ&~x)
%     t &= ~x
%   end
%   return bases
% end
% \end{jllisting}
% \textbf{Minimal spanning subsets and bases.} \skelpar