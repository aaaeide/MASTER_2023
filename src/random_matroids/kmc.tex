\section{Knuth's matroid construction}
\label{sec:kmc}
In the preparatory project to this thesis, delivered to my advisor in the fall of 2022, I implemented Knuth's 1974 algorithm for the random generation of arbitrary matroids via the erection of closed sets \cite{knuth-1975}. With this, I was able to randomly generate matroids of universe sizes $n \leq 12$, but for larger values of $n$ my implementation was unbearably slow. In this section, Knuth's method for random matroid construction will be described, along with the steps I have taken to speed up my initial, na√Øve implementation.

\pr{Knuth-Matroid} (given in Algorithm~\ref{alg:knuth}) accepts the ground set $E$ and a list $\mathrm{X}$ such that $\mathrm{X}[i] \subseteq 2^E$, and produces the rank-$r$ matroid $\mathfrak{M}$ such that $\mbox{rank}(X) = k$ for each $X \in \mathrm{X}[k]$. This is done in a bottom-up manner through $r$ sequential erections starting from the empty rank-0 matroid, $\mathfrak{M}^{(0)}$, each iteration $i$ producing the erection $\mathfrak{M}^{(i+1)}$ from $\mathfrak{M}^{(i)}$ and $\mathrm{X}[i]$. The algorithm outputs the tuple $(E, \mathrm{F})$, where $\mathrm{F} = [F_0, \ldots, F_r]$, $r$ being the final rank of $\mathfrak{M}$ and $F_i$ the family of closed sets of rank $i$. In the paper, Knuth shows that $\bigcup_{i=0}^r \mathrm{F}[r] = \mathcal{F}$, where $\mathcal{F}$ is the set of closed sets of a matroid, and so the algorithm produces a valid matroid represented by its closed sets.

To understand the procedure, let us investigate what Algorithm~\ref{alg:knuth} does at iteration $1<i<r$, where $r$ is the final rank $\mathfrak{M}$, the matroid under construction. At iteration $i$, we produce a rank-$(i+1)$ erection $\mathfrak{M}^{(i+1)}$ of $\mathfrak{M}^{(i)}$, which is represented by its closed sets $\mathrm{F} = [F_0, F_1, ..., F_i]$, where $F_i$ is the set of closed sets of rank $i$. We want to produce the set $F_{i+1}$ of rank-$r$ closed sets of an erection of $\mathfrak{M}^{(i)}$ such that each $X \in \mathrm{X}[i]$ is contained in some rank-$r$ closed set. First we find the ``covers'' of each closed set in $F_i$. The covers of a closed set $A$ of rank $r$ are the sets obtained by adding one more element from $E$ to $A$. The covers are generated with \pr{Generate-Covers}(\mathrm{F}, r, E).

\include{src/random_matroids/kmc.pseudo}

Given no enlargements ($\mathrm{X}[i] = \emptyset$), the resulting matroid $\mathfrak{M}^{(i+1)}$ is the \textit{free erection} of $\mathfrak{M}^{(i)}$, and there are no essential closed sets in $F_{i+1}$. Arbitrary matroids can be generated by supplying different lists $\mathrm{X}$. When enlarging, the sets in $\mathrm{X}[r+1]$ are simply added to $\mathrm{F}[r+1]$, before \pr{Superpose!} is run to ensure that the newly enlarged family of closed sets of rank $r+1$ is valid (ie. in accordance with the closed set axioms given in Section~\ref{sec:matroid-theory}). If $F_{r+1}$ contains two sets $A,B$ whose intersection $A \cap B \not \subseteq C$ for any $C \in F_{r}$ (in other words, their intersection is not a closed set), replace $A,B$ with $A \cup B$. Repeat until no two sets exist in $F_{r+1}$ whose intersection is not contained within some set $C \in F_{r}$.

\begin{figure}[ht!]
  \centering
  \resizebox{\columnwidth}{!}{
         \begin{tikzpicture}[> = stealth,  shorten > = 1pt,   auto,   node distance = 1.5cm, mynode/.style={pattern=north east lines, circle, draw,inner sep=2pt,outer sep=0pt}]
  
  %%% LEVEL 1
  \node[draw, mynode, fill=darktan]  (x) {1111};
  %%% LEVEL 2
  \node[draw, mynode, fill=complementaryblue]  [below left of=x] (B) {1101};
  \node[draw, mynode, fill=complementaryblue] [below right of=x]  (C) {1011};
  \node[draw, mynode, fill=complementaryblue]  [left  of=B] (A) {1110};
  \node[draw, mynode, fill=darktan] [right of=C]  (D) {0111};
  %%%% LEVEL 3
  \node[draw, mynode, fill=complementaryblue] [below of=B]  (AD) {0110};
  \node[draw, mynode, fill=averagegreen] [below of=C]  (BC) {1001};
  \node[draw, mynode, fill=complementaryblue] [below of=D]  (BD) {0101};
  \node[draw, mynode, fill=averagegreen] [below of=A]  (AC) {1010};
  \node[draw, mynode, fill=averagegreen] [left  of=AC] (AB) {1100};
  \node[draw, mynode, fill=complementaryblue] [right of=BD] (CD) {0011};
  
  %%  LEVEL   4
  \node[draw, mynode, fill=averagegreen] [below of=AD]  (ABD) {0100};
  \node[draw, mynode, fill=averagegreen] [below of=BC]  (ACD) {0010};
  \node[draw, mynode, fill=averagegreen] [left of=ABD]  (ABC) {1000};
  \node[draw, mynode, fill=averagegreen] [right of=ACD] (BCD) {0001};
  
  %%%% LEVEL 5
  \node[draw, mynode, fill=averagegreen] [below right of=ABD]  (ABCD) {0000};

  \begin{scope}[on background layer]
    \draw[line width=2mm, darktan] (D) to (AD);
    \draw[line width=2mm, darktan] (D) to (BD);
    \draw[line width=2mm, darktan] (D) to (CD);
  \end{scope}
  
  
  %% LEVEL 1 to LEVEL 2
      \path (x)  edge [preaction={draw=darktan, line width=2mm}] (A);
      \path (x)  edge [preaction={draw=darktan, line width=2mm}] (B);
      \path (x)  edge [preaction={draw=darktan, line width=2mm}] (C);
      \path (x)  edge (D);
  
  %% LEVEL 2 to LEVEL 3
      \draw (A)  -- (AB);
      \draw (A)  -- (AC);
      \draw (A)  -- (AD);
      \draw (B)  -- (AB);
      \draw (B)  -- (BC);
      \draw (B)  -- (BD);
      \draw (C)  -- (AC);
      \draw (C)  -- (BC);
      \draw (C)  -- (CD);
      \draw (D)  -- (AD);
      \draw (D)  -- (BD);
      \draw (D)  -- (CD);
  %%% LEVEL 3 TO 4
  
      \draw (AB)  -- (ABC);
      \draw (AB)  -- (ABD);
      \draw (AC)  -- (ABC);
      \draw (AC)  -- (ACD);
      \draw (AD)  -- (ABD);
      \draw (AD)  -- (ACD);
      \draw (BC)  -- (ABC);
      \draw (BC)  -- (BCD);
      \draw (BD)  -- (ABD);
      \draw (BD)  -- (BCD);
      \draw (CD)  -- (ACD);
      \draw (CD)  -- (BCD);
  %%%% LEVEL 4 to 5
      \draw (ABC)  -- (ABCD);
      \draw (ABD)  -- (ABCD);
      \draw (ACD)  -- (ABCD);
      \draw (BCD)  -- (ABCD);
      
      %%%% Dashed lines
% \draw[dashed] (-6,-0.5) -- (6,-0.5); 
% \node[] at (-6,0) {Rank 4};
\draw[dashed] (-6,-1.75) -- (1.75,-1.75); 
\draw[dashed] (1.75,-1.75) -- (1.75,-0.25); 
\draw[dashed] (1.75,-0.25) -- (6,-0.25); 
\node[] at (-6,-1) {Rank 3};
\draw[dashed] (-6,-3.5) -- (6,-3.5); 
\node[] at (-6,-2.625) {Rank 2};
\draw[dashed] (-6,-4.625) -- (6,-4.625); 
\node[] at (-6,-4) {Rank 1};
\node[] at (-6,-5) {Rank 0};

        \end{tikzpicture}
  }
  \caption{A matroid-under-construction. The set 0111 has just been assigned as a closed set of rank 2.}
  \label{fig:kmc-ex-1}
\end{figure}
To cement our intuitive understanding of Knuth's matroid erection algorithm, we revisit the example from Chapter~2. Figure~\ref{fig:kmc-ex-1} shows the Hasse diagram of a matroid, the sets represented as binary strings where a 1-digit at position $i$ signifies that element $i$ is present in the set. A blue set is independent and a yellow set is dependent; a green set is both (i.e. both maximal and minimal for its rank). The edges marked in yellow signify the closure of a set. A set with no yellow edges going up and out of it is maximal for its rank (i.e., closed). The situation illustrated is in the second iteration of KMC. The set 0111 has just been designated as a closed set of rank 2. 

Let the next element in $\mathrm{X}[2]$ be the set 1011---this is the next set we are designating as a rank-2 closed set. Figure~\ref{fig:kmc-ex-2} shows the situation after adding this. This situation is problematic, and we can think about why in several ways. Firstly, the intersection of these two closed sets, $1011\cap0111=0011$ (marked in grey) is not itself a closed set, breaking an axiom for the closed sets of a matroid. Secondly, the rank-2 independent set 0011 has two outgoing yellow edges---which represents the closure of 0011? Finally, consider the exchange property of independent sets: if $S$ and $T$ are independent sets with $|S|>|T|$, then there exists an element $g\in S\setminus T$ such that $T + g$ is independent (and of increased rank). The independent set 1101 is bigger than 0011, yet no element from the first can be added to the second to produce a bigger independent set. In the situation as it stands at this point, the independent set 0011 is a ``blind alley'' that cannot grow in rank, even though other independent sets of larger rank exist. 

It is this situation that the \pr{Superpose!} operation detects, and the two errant closed sets 1011 and 0111 are merged, replaced with $1011\cup0111=1111$ as a closed set of rank 2. When this happens, the algorithm terminates, as we have found the rank of the ground set, and all sets of size larger than 2 are dependent. The final matroid is given in Figure~\ref{fig:kmc-ex-3}.

\begin{figure}
  \centering
  \resizebox{\columnwidth}{!}{
         \begin{tikzpicture}[> = stealth,  shorten > = 1pt,   auto,   node distance = 1.5cm, mynode/.style={pattern=north east lines, circle, draw,inner sep=2pt,outer sep=0pt}]
  
  %%% LEVEL 1
  \node[draw, mynode, fill=darktan]  (x) {1111};
  %%% LEVEL 2
  \node[draw, mynode, fill=complementaryblue]  [below left of=x] (B) {1101};
  \node[draw, mynode, fill=darktan] [below right of=x]  (C) {1011};
  \node[draw, mynode, fill=complementaryblue]  [left  of=B] (A) {1110};
  \node[draw, mynode, fill=darktan] [right of=C]  (D) {0111};
  %%%% LEVEL 3
  \node[draw, mynode, fill=complementaryblue] [below of=B]  (AD) {0110};
  \node[draw, mynode, fill=complementaryblue] [below of=C]  (BC) {1001};
  \node[draw, mynode, fill=complementaryblue] [below of=D]  (BD) {0101};
  \node[draw, mynode, fill=complementaryblue] [below of=A]  (AC) {1010};
  \node[draw, mynode, fill=averagegreen] [left  of=AC] (AB) {1100};
  \node[draw, mynode] [right of=BD] (CD) {0011};
  
  %%  LEVEL   4
  \node[draw, mynode, fill=averagegreen] [below of=AD]  (ABD) {0100};
  \node[draw, mynode, fill=averagegreen] [below of=BC]  (ACD) {0010};
  \node[draw, mynode, fill=averagegreen] [left of=ABD]  (ABC) {1000};
  \node[draw, mynode, fill=averagegreen] [right of=ACD] (BCD) {0001};
  
  %%%% LEVEL 5
  \node[draw, mynode, fill=averagegreen] [below right of=ABD]  (ABCD) {0000};

  \begin{scope}[on background layer]
    % \draw[line width=2mm, darktan] (A) to (AB);
    % \draw[line width=2mm, darktan] (A) to (AC);
    % \draw[line width=2mm, darktan] (A) to (AD);
    % \draw[line width=2mm, darktan] (B) to (AB);
    % \draw[line width=2mm, darktan] (B) to (BC);
    % \draw[line width=2mm, darktan] (B) to (BD);
    \draw[line width=2mm, darktan] (C) to (AC);
    \draw[line width=2mm, darktan] (C) to (BC);
    \draw[line width=2mm, darktan] (C) to (CD);
    \draw[line width=2mm, darktan] (D) to (AD);
    \draw[line width=2mm, darktan] (D) to (BD);
    \draw[line width=2mm, darktan] (D) to (CD);
    
    % \draw[line width=2mm, darktan] (AB) to (ABC);
    % \draw[line width=2mm, darktan] (AB) to (ABD);
    % \draw[line width=2mm, darktan] (AC) to (ABC);
    % \draw[line width=2mm, darktan] (AC) to (ACD);
    % \draw[line width=2mm, darktan] (AD) to (ABD);
    % \draw[line width=2mm, darktan] (AD) to (ACD);
    % \draw[line width=2mm, darktan] (BC) to (ABC);
    % \draw[line width=2mm, darktan] (BC) to (BCD);
    % \draw[line width=2mm, darktan] (BD) to (ABD);
    % \draw[line width=2mm, darktan] (BD) to (BCD);
    % \draw[line width=2mm, darktan] (CD) to (ACD);
    % \draw[line width=2mm, darktan] (CD) to (BCD);
  \end{scope}
  
  
  %% LEVEL 1 to LEVEL 2
      \path (x)  edge [preaction={draw=darktan, line width=2mm}] (A);
      \path (x)  edge [preaction={draw=darktan, line width=2mm}] (B);
      \path (x)  edge (C);
      \path (x)  edge (D);
  
  %% LEVEL 2 to LEVEL 3
      \draw (A)  -- (AB);
      \draw (A)  -- (AC);
      \draw (A)  -- (AD);
      \draw (B)  -- (AB);
      \draw (B)  -- (BC);
      \draw (B)  -- (BD);
      \draw (C)  -- (AC);
      \draw (C)  -- (BC);
      \draw (C)  -- (CD);
      \draw (D)  -- (AD);
      \draw (D)  -- (BD);
      \draw (D)  -- (CD);
  %%% LEVEL 3 TO 4
  
      \draw (AB)  -- (ABC);
      \draw (AB)  -- (ABD);
      \draw (AC)  -- (ABC);
      \draw (AC)  -- (ACD);
      \draw (AD)  -- (ABD);
      \draw (AD)  -- (ACD);
      \draw (BC)  -- (ABC);
      \draw (BC)  -- (BCD);
      \draw (BD)  -- (ABD);
      \draw (BD)  -- (BCD);
      \draw (CD)  -- (ACD);
      \draw (CD)  -- (BCD);
  %%%% LEVEL 4 to 5
      \draw (ABC)  -- (ABCD);
      \draw (ABD)  -- (ABCD);
      \draw (ACD)  -- (ABCD);
      \draw (BCD)  -- (ABCD);
      
      %%%% Dashed lines
% \draw[dashed] (-6,-0.5) -- (6,-0.5); 
% \node[] at (-6,0) {Rank 4};
\draw[dashed] (-6,-1.75) -- (-0.5,-1.75); 
\draw[dashed] (-0.5,-1.75) -- (0.75,-0.25); 
\draw[dashed] (0.75,-0.25) -- (6,-0.25); 
\node[] at (-6,-1) {Rank 3};
\draw[dashed] (-6,-3.5) -- (6,-3.5); 
\node[] at (-6,-2.625) {Rank 2};
\draw[dashed] (-6,-4.625) -- (6,-4.625); 
\node[] at (-6,-4) {Rank 1};
\node[] at (-6,-5) {Rank 0};

        \end{tikzpicture}
  }
  \caption{The set 1011 has been added as a rank-2 closed set in the matroid-under-construction from Figure~\ref{fig:kmc-ex-1}. This is not a valid matroid.}
  \label{fig:kmc-ex-2}
\end{figure}


\begin{figure}\centering
  \resizebox{\columnwidth}{!}{
         \begin{tikzpicture}[> = stealth,  shorten > = 1pt,   auto,   node distance = 1.5cm, mynode/.style={pattern=north east lines, circle, draw,inner sep=2pt,outer sep=0pt}]
  
  %%% LEVEL 1
  \node[draw, mynode, fill=darktan]  (x) {1111};
  %%% LEVEL 2
  \node[draw, mynode, fill=darktan]  [below left of=x] (B) {1101};
  \node[draw, mynode, fill=darktan] [below right of=x]  (C) {1011};
  \node[draw, mynode, fill=darktan]  [left  of=B] (A) {1110};
  \node[draw, mynode, fill=darktan] [right of=C]  (D) {0111};
  %%%% LEVEL 3
  \node[draw, mynode, fill=complementaryblue] [below of=B]  (AD) {0110};
  \node[draw, mynode, fill=complementaryblue] [below of=C]  (BC) {1001};
  \node[draw, mynode, fill=complementaryblue] [below of=D]  (BD) {0101};
  \node[draw, mynode, fill=complementaryblue] [below of=A]  (AC) {1010};
  \node[draw, mynode, fill=complementaryblue] [left  of=AC] (AB) {1100};
  \node[draw, mynode, fill=complementaryblue] [right of=BD] (CD) {0011};
  
  %%  LEVEL   4
  \node[draw, mynode, fill=averagegreen] [below of=AD]  (ABD) {0100};
  \node[draw, mynode, fill=averagegreen] [below of=BC]  (ACD) {0010};
  \node[draw, mynode, fill=averagegreen] [left of=ABD]  (ABC) {1000};
  \node[draw, mynode, fill=averagegreen] [right of=ACD] (BCD) {0001};
  
  %%%% LEVEL 5
  \node[draw, mynode, fill=averagegreen] [below right of=ABD]  (ABCD) {0000};

  \begin{scope}[on background layer]
    \draw[line width=2mm, darktan] (x) to (A);
    \draw[line width=2mm, darktan] (x) to (B);
    \draw[line width=2mm, darktan] (x) to (C);
    \draw[line width=2mm, darktan] (x) to (D);
    \draw[line width=2mm, darktan] (A) to (AB);
    \draw[line width=2mm, darktan] (A) to (AC);
    \draw[line width=2mm, darktan] (A) to (AD);
    \draw[line width=2mm, darktan] (B) to (AB);
    \draw[line width=2mm, darktan] (B) to (BC);
    \draw[line width=2mm, darktan] (B) to (BD);
    \draw[line width=2mm, darktan] (C) to (AC);
    \draw[line width=2mm, darktan] (C) to (BC);
    \draw[line width=2mm, darktan] (C) to (CD);
    \draw[line width=2mm, darktan] (D) to (AD);
    \draw[line width=2mm, darktan] (D) to (BD);
    \draw[line width=2mm, darktan] (D) to (CD);
  \end{scope}
  
  
  %% LEVEL 1 to LEVEL 2
      \path (x)  edge node {} (A);
      \path (x)  edge node {} (B);
      \path (x)  edge node {} (C);
      \path (x)  edge node {} (D);
  
  %% LEVEL 2 to LEVEL 3
      \path (A)  edge node {} (AB);
      \path (A)  edge node {} (AC);
      \path (A)  edge node {} (AD);
      \path (B)  edge node {} (AB);
      \path (B)  edge node {} (BC);
      \path (B)  edge node {} (BD);
      \path (C)  edge node {} (AC);%
      \path (C)  edge node {} (BC);
      \path (C)  edge node {} (CD);
      \path (D)  edge node {} (AD);
      \path (D)  edge node {} (BD);
      \path (D)  edge node {} (CD);
  %%% LEVEL 3 TO 4
  
      \path (AB)  edge node {} (ABC);
      \path (AB)  edge node {} (ABD);
      \path (AC)  edge node {} (ABC);
      \path (AC)  edge node {} (ACD);
      \path (AD)  edge node {} (ABD);
      \path (AD)  edge node {} (ACD);
      \path (BC)  edge node {} (ABC);
      \path (BC)  edge node {} (BCD);
      \path (BD)  edge node {} (ABD);
      \path (BD)  edge node {} (BCD);
      \path (CD)  edge node {} (ACD);
      \path (CD)  edge node {} (BCD);
  %%%% LEVEL 4 to 5
      \path (ABC)  edge node {} (ABCD);
      \path (ABD)  edge node {} (ABCD);
      \path (ACD)  edge node {} (ABCD);
      \path (BCD)  edge node {} (ABCD);

      %%%% Dashed lines
% \draw[dashed] (-6,-0.5) -- (6,-0.5); 
% \node[] at (-6,0) {Rank 4};
% \draw[dashed] (-6,-1.75) -- (6,-1.75); 
% \node[] at (-6,-1) {Rank 3};
\draw[dashed] (-6,-3.5) -- (6,-3.5); 
\node[] at (-6,-2.625) {Rank 2};
\draw[dashed] (-6,-4.625) -- (6,-4.625); 
\node[] at (-6,-4) {Rank 1};
\node[] at (-6,-5) {Rank 0};

        \end{tikzpicture}
  }
  \caption{The uniform matroid $U_4^2$.}
  \label{fig:kmc-ex-3}
\end{figure}


\subsection{Randomized KMC}
In the randomized version of \pr{Knuth-Matroid}, we generate matroids by applying a supplied number of random coarsening steps, instead of enlarging with supplied sets. This is done by applying \pr{Superpose!} immediately after adding the covers, then choosing a random member $A$ of $\mathrm{F}[r+1]$ and a random element $a \in E \setminus A$, replacing $A$ with $A \cup \{a\}$ and finally reapplying \pr{Superpose!}. The parameter $p = (p_1, p_2, \ldots)$ gives the number of such coarsening steps to be applied at each iteration of the algorithm.

The pseudocode descriptions of Knuth's matroid construction hews closely to the initial Julia implementation. It should already be clear that this brute force approach leads to poor performance---for instance, the \pr{Superpose!} method uses a triply nested for loop, which seems like a candidate for significant improvement. Section~\ref{sec:improving-performance} describes the engineering work done to create a more performant implementation.

\begin{algorithm}[float*=ht!]{\pr{Randomized-Knuth-Matroid}(E, p)}{rkmc}

  \textbf{Input:}     \tab The ground set of elements $E$, and a list $p = [p_1, p_2, ...]$, where \\
  \mbox{}\tab $p_r$ is the number of coarsening steps to apply at rank $r$ in the \\
  \mbox{}\tab construction.

  \textbf{Output:}    \tab The list of closed sets of the resulting matroid grouped by rank, \\
  \mbox{}\tab $\mathrm{F} = [F_0, \ldots, F_r]$, where $F_i$ is the set of closed sets of rank $i$.

  \begin{pseudo}[label=\small\arabic*, indent-mark, line-height=1.2]
    $r = 0, \mathrm{F} = [\{ \emptyset \}]$ \\
    \kw{while} \cn{true}  \\+
      $\pr{Push!}(\mathrm{F}, \pr{Generate-Covers}(\mathrm{F}, r, E))$ \\
      \pr{Superpose!}(\mathrm{F}[r+1], \mathrm{F}[r]) \\
      
      \kw{if} $E \in \mathrm{F}[r+1]$ \kw{return} $(E, \mathrm{F})$ \\
      
      \kw{while} $p[r] > 0$ \\+
        $A \leftarrow$ a random set in $\mathrm{F}[r+1]$ \\
        $a \leftarrow$ a random element in $E \setminus A$ \\
        \kw{replace} $A$ with $A \cup \{a\}$ in $\mathrm{F}[r+1]$ \\
        \pr{Superpose!}(\mathrm{F}[r+1], \mathrm{F}[r]) \\

        \kw{if} $E \in \mathrm{F}[r+1]$ \kw{return} $(E, \mathrm{F})$ \\

        $p[r] = p[r] - 1$ \\-
      $r = r + 1$

  \end{pseudo}

\end{algorithm}


\subsection{Improving performance}
\label{sec:improving-performance}
In the preparatory project to this thesis, I was able to recreate Knuth's table of observed mean values for the randomly generated matroids, but I was dismayed to find that my implementation was unable to handle matroids whose ground sets were even just a few elements larger. Considering that Knuth was able to run his experiments on the hardware available to him in the 1970s, I concluded that my implementation had room for improvement. Table~\ref{tab:perf_v1} shows the performance of my first implementation. Even for rank-5 matroids of only 12 elements, this implementation is intolerably slow. For readability's sake, I have moved all lengty code snippets to Appendix~\ref{apx:rkmc_dev}; the initial Julia implementation can be found in Figures~\ref{code:rkmc_v1_a} and \ref{code:rkmc_v1_b}. In this section, I describe some of the implementation decisions that were made to improve this performance.

\begin{table}
  \centering
    \begin{tabular}{cccccc}
      \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & $r$ & Time & Bytes allocated \\
      \midrule
      10 & (0, 6)     & 380  & 4.0  & 158.1ms & 149.713 MiB   \\
      10 & (0, 0, 6)  & 22   & 4.4  & 2.8s    & 2.481 GiB     \\
      12 & (0, 7)     & 21   & 5.1  & 3.4s    & 2.773 GiB     \\
      12 & (0, 0, 7)  & 2    & 5.0  & 43.9s   & 36.753 GiB    \\
      \bottomrule
    \end{tabular}
  \caption{Performance of $\texttt{random\_kmc\_v1}$.}
  \label{tab:perf_v1}
\end{table}

The performance was measured using Julia's \jlinl{@timed}\footnote{\href{https://docs.julialang.org/en/v1/base/base/\#Base.@timed}{https://docs.julialang.org/en/v1/base/base/\#Base.@timed}} macro, which returns the time it takes to execute a function call, how much of that time was spent in garbage collection and the number of bytes allocated. The experiments was run on a 2021 MacBook Pro with the Apple M1 chip and 16GB RAM. As is evident from the data, larger matroids are computationally quite demanding to compute with this current approach, and the time and space requirements scales exponentially with $n$.

The tables in this section give the median time and memory performance, as well as average resulting matroid rank, of subsequent versions of my implementation of \pr{Random-Knuth-Matroid}. The experiments are set up with increasing values for $n$ and $p$, in a manner to produce matroids of larger rank over larger ground sets. Each experiment is repeated for as many trials as can fit within one minute. The runtime of the random matroid generation functions varies quite a bit depending on which sets are chosen for coarsening, and so for situations where an experiment is run only a few times, the average time might be a bit misleading. The data is presented in order to show that the improvements described in this section are in fact meaningful optimizations.

\subsubsection{Representing sets as binary numbers}
The first improvement we will attempt is to represent our closed sets using one of Julia's \jlinl{Integer} types of bit width at least $n$, instead of as a \jlinl{Set}\footnote{\href{https://docs.julialang.org/en/v1/base/collections/\#Base.Set}{https://docs.julialang.org/en/v1/base/collections/\#Base.Set}} of elements of $E$. The idea is to define a family of closed sets of the same rank as \jlinl{Set\{UInt16\}}. Using \jlinl{UInt16} we can support ground sets of size up to 16. Each 16-bit number represents a set in the family. For example, the set $\{ 2,5,7 \}$ is represented by $$164 = 0\rm{x}00\rm{a}4 = 0\rm{b}0000000010100100 = 2^7+2^5+2^2.$$ At either end we have $\emptyset \equiv 0\rm{x}0000$ and $E \equiv 0\rm{xffff}$ (if $n = 16$). The elementary set operations we will need have simple implementations using bitwise operations:

\begin{table}
  % \caption{Set operations and their equivalent bitwise operations}
  \centering
  \begin{tabular}{|l|l|}
  \hline
      Set operation & Bitwise operation \\\hline
      $A \cap B$      & $A$ AND $B$ \\\hline
      $A \cup B$      & $A$ OR $B$ \\\hline
      $A \setminus B$ & $A$ AND NOT $B$ \\\hline
      $A \subseteq B$ & $A$ AND $B$ = $A$ \\\hline
  \end{tabular}
  \caption{Set operations and their corresponding bitwise operations}
\end{table}

We can now describe the bitwise versions of the required methods. The bitwise implementation of \pr{Generate-Covers} finds all elements in $E \setminus A$ by finding each value $0\leq i< n$ for which \jlinl{A & 1 << i === 0}, meaning that the set represented by \jlinl{1 << i} is not a subset of A. The bitwise implementation of \pr{Superpose!} is unchanged apart from using the bitwise set operations described above. The source code for these is given in Figure~\ref{code:rkmc_v2}.

\begin{table}
  \centering
  \begin{tabular}{cccccc}
    \toprule
    $n$ & $(p_1, p_2, \ldots)$ & Trials & $r$ & Time  & Bytes allocated \\
    \midrule
    10 & (0, 6)     & 39975 & 3.85 & 1.5ms    & 1.646 MiB     \\
    10 & (0, 0, 6)  & 6277  & 4.56 & 9.6ms    & 7.510 MiB     \\
    12 & (0, 7)     & 7337  & 3.98 & 8.2ms    & 5.406 MiB     \\
    12 & (0, 0, 7)  & 765   & 4.52 & 78.5ms   & 38.274 MiB    \\
    16 & (0, 8)     & 89    & 5.31 & 674.3ms  & 103.595 MiB   \\
    \bottomrule
  \end{tabular}
  \caption{Performance of $\texttt{random\_kmc\_v2}$.}
  \label{tab:perf_v2}
\end{table}

The performance of \jlinl{random\_kmc\_v2} is shown in Table~\ref{tab:perf_v2}. It is clear that representing closed sets using binary numbers represents a substantial improvement---we are looking at performance increases on the order of 100x across the board.


\subsubsection{Sorted superpose}
Can we improve the running time of our implementation further? It is clear that \pr{Superpose!} takes up a large portion of the compute time. In the worst case, when no enlargements have been made, $F_{r+1}$ is the set of all $r+1$-sized subsets of $E$, $|F_{r+1}| = {\binom{n}{r+1}}$. Comparing each $A,B \in F_{r+1}$ with each $C \in F_r$ in a triply nested for loop requires $O({\binom{n}{r+1}}^2{\binom{n}{r}})$ operations. In the worst case, no enlargements are made at all, and we build the free matroid in $O(2^{3n})$ time (considering only the superpose step).

After larger closed sets have been added to $\mathrm{F}[r+1]$, \pr{Superpose!} will cause sets to merge, so that only maximal dependent sets remain. Some sets will even simply disappear. In the case where $X=\{1,2\}$ was added by \pr{Generate-Covers}, and the $Y=\{1,2,3\}$ was added manually as an enlargement, the smaller set will be fully subsumed in the bigger set, as $\{1,2\}\cap\{1,2,3\}=\{1,2\}$ (which is not a subset of any set in $\mathrm{F}[r]$) and $\{1,2\}\cup\{1,2,3\}=\{1,2,3\}$. In this situation, $Y$ would ``eat'' the covers $\{1,3\}$ and $\{2,3\}$ as well. This fact is reflected in the performance data -- compare the memory allocation differences between the 10-element matroid with $p=[0,0,6]$ and the one with $p=[0,6,0]$ in any of the performance tables in this section. Making enlargements at earlier ranks result in smaller matroids as more sets get absorbed.

Since the larger sets will absorb so many of the smaller sets (around $\binom{p}{r+1}$, where $p$ is the size of the larger set and $r+1$ is the size of the smallest sets allowed to be added in a given iteration), might it be an idea to perform the superpose operation in descending order based on the size of the sets? This should result in fewer calls to \pr{Superpose!}, as the bigger sets will remove the smaller sets that fully overlap with them in the early iterations, however, the repeated sorting of the sets might negate this performance gain. This is the idea behind \jlinl{random_kmc_v3}. The source code for the sorted superpose function is given in Figure~\ref{code:rkmc_v3}.

Unfortunately, as Table~\ref{tab:perf_v3} shows, this implementation is not an especially significant improvement, though it performs somewhat better than the previous version on the later tests. What if we rethink the superpose operation more fundamentally?

\begin{table}
  \centering
  \begin{tabular}{cccccc}
    \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & $r$   & Time    & Bytes allocated \\
    \midrule
      10  & (0, 6)               & 19183  & 3.85  & 3.1ms   & 3.881 MiB     \\
      10  & (0, 0, 6)            & 4009   & 4.53  & 15.0ms  & 14.562 MiB     \\
      12  & (0, 7)               & 4722   & 3.97  & 12.7ms  & 10.781 MiB     \\
      12  & (0, 0, 7)            & 613    & 4.52  & 97.9ms  & 60.336 MiB     \\
      16  & (0, 8)               & 189    & 5.41  & 364.8ms & 119.229 MiB     \\
      16  & (0, 0, 8)            & 18     & 5.44  & 3.4s    & 717.923 MiB     \\
      20  & (0, 9)               & 2      & 9.0   & 35.0    & 4.597 GiB     \\
      \bottomrule
    \end{tabular}
  \caption{Performance of $\texttt{random\_kmc\_v3}$.}
  \label{tab:perf_v3}
\end{table}


\subsubsection{Iterative superpose}
The worst-case $O({\binom{n}{r+1}}^2{\binom{n}{r}})$ runtime of \pr{Superpose!} at step $r$ is due to the fact that it takes in $\mathrm{F}$ after all covers and enlargements have been indiscriminately added to $\mathrm{F}[r+1]$ and then loops through to perform the superposition. Might there be something to gain by inserting new closed sets into the current family one at a time, and superposing on the fly?

\begin{figure}
\begin{jllisting}
  # Superpose (random_kmc_v4)
  push!(F, Set()) # Add F[r+1].
  while length(to_insert) > 0
    A = pop!(to_insert)
    push!(F[r+1], A)

    for B in setdiff(F[r+1], A)
      if should_merge(A, B, F[r])
        push!(to_insert, A | B)
        setdiff!(F[r+1], [A, B])
        push!(F[r+1], A | B)
      end
    end
  end
\end{jllisting}
\caption{\jlinl{random_kmc_v4}: On-the-fly superposition.}
\end{figure}

In \jlinl{random_kmc_v4}, the full code of which can be found in Figure~\ref{code:rkmc_v4}, the covers and enlargements are not added directly to $\mathrm{F}[r+1]$, but to a temporary array \jlinl{to_insert}. Each set $A$ is then popped from \jlinl{to_insert} one at a time, added to $\mathrm{F}[r+1]$ and compared with the other sets $B \in \mathrm{F}[r+1] \setminus \{A\}$ and $C \in \mathrm{F}[r]$ in the usual \pr{Superpose!} manner. This results in fewer comparisons, as each set is only compared with the sets added before it; the first set is compared with no other sets, the second set with one other and the sets in $\mathrm{F}[r]$, and so on. The number of such comparisons is therefore given by the triangular number $T_{\binom{n}{r+1}}$, and so we should have roughly halved the runtime at step $r$. It is worth noting that this implementation of \pr{Superpose!} uses a subroutine \jlinl{should_merge} that returns early when it finds one set $C \in \mathrm{F}[r]$ such that $C \supseteq A \cap B$, so in practice it usually does not require $\binom{n}{r}$ comparisons in the innermost loop.

Table~\ref{tab:perf_v4} shows that the iterative superpose was a meaningful improvement. For most input configurations, it is a few times faster and a few times less space demanding than \jlinl{random_kmc_v2}.


\begin{table}
  \centering
  \begin{tabular}{cccccc}
    \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & $r$   & Time    & Bytes allocated \\
    \midrule
      10  & (0, 6)    & 95004  & 4.54  & 631.6\unit{\us} & 438.354 KiB     \\
      10  & (0, 0, 6) & 26947  & 4.94  & 2.2ms           & 1.103 MiB     \\
      12  & (0, 7)    & 18780  & 4.99  & 3.2ms           & 1.553 MiB     \\
      12  & (0, 0, 7) & 3438   & 5.14  & 17.5ms          & 5.210 MiB     \\
      16  & (0, 8)    & 450    & 6.71  & 134.0ms         & 30.372 MiB     \\
      16  & (0, 0, 8) & 75     & 6.12  & 814.9ms         & 101.836 MiB     \\
      20  & (0, 9)    & 9      & 8.78  & 10.0s           & 847.919 MiB     \\
      20  & (0, 0, 9) & 2      & 8.5   & 389.6s          & 9.446 GiB     \\
      24  & (0, 10)   & 1      & 11.0  & 189.6s          & 9.709 GiB     \\
    \bottomrule
    \end{tabular}
  \caption{Performance of $\texttt{random\_kmc\_v4}$.}
  \label{tab:perf_v4}
\end{table}

\subsubsection{Rank table and non-redundant cover generation}
Up to this point, our cover generation routine has not taken into account that any two sets of rank $r$ will have at least one cover in common. To see this, consider a matroid-under-construction with $n=10$ where $A = \{1,2\}$ and $B = \{1,3\}$ are closed sets of rank 2. Currently, \pr{Generate-Covers} will happily generate the cover $C=\{1,2,3\}$ twice, once as the cover of $A$ and subsequently as the cover of $B$. Throughout this analysis, we will assume the worst case scenario of no enlargements, as any enlargements will strictly lower the number of sets in play at a given rank. In this case, $|\mathrm{F}[r]| = \binom{n}{r}$, and for each closed set $A$ of rank $r$ we are generating $|E\setminus A| = (n-r)$ covers, giving us a total of $\binom{n}{r}(n-r)$ covers generated at each rank $r$, including the duplicates. With no enlargements, we know that there are $\binom{n}{r+1}$ covers, and

$$\begin{aligned}
  (n-r)\binom{n}{r} &= \frac{n!(n-r)}{r!(n-r)!} \\
                    &= \frac{n!}{r!(n-r-1)!} \\
                    &= (r+1)\frac{n!}{(r+1)!(n-r-1)!} \\
                    &= (r+1)\binom{n}{r+1}. \\
\end{aligned}$$
For each step $r$, we are generating $r+1$ times as many covers as we need to. Over the course of all steps $0\leq r\leq n$, we are generating $$\sum_{r=0}^n (r+1) = \sum_{r=1}^{n+1}r = T_{n+1}$$ times the actual number of covers, where $T_{n+1}=\frac{(n+1)(n+2)}{2}$ is the triangular number. In other words, if we find a way to generate each cover only once, we will have shaved off an $n^2$ factor from the asymptotic complexity of our implementation.

When generating covers, \jlinl{random_kmc_v6} improves upon the brute force cover generation described above by only adding the covers 
$$\Bigl\{ A \cup \{ a \} : A \in \mathrm{F}[r], a \in E \setminus A, a \notin \bigcup \bigl\{ B : B \in \mathrm{F}[r+1], A \subseteq B \bigr\} \Bigr\}.$$
In other words, we find the covers of $A$, that is, the sets obtained by adding one more element $a$ from $E$ to $A$, but we do not include any $a$ that is to be found in another, already added, cover $B$ that contains $A$. This solves the problem described above; the cover $\{1,2,3\} = B \cup \{ 2 \}$ will not be generated, as $2 \in C$ and $B \subseteq C$. Figure~\ref{code:smart_covers} shows an implementation of this.

\begin{figure}
\begin{jllisting}
function generate_covers!(F, r, E, insert_fn)
  for y in F[r]
    t = E - y
    # Find all sets in F[r+1] that already contain y and remove excess elements from t.
    for x in F[r+1]
      if (x & y == y) t &= ~x end
      if t == 0 break end
    end
    # Insert y ‚à™ a for all a ‚àà t.
    while t > 0
      x = y|(t&-t)
      insert_fn(x)
      t &= ~x
    end
  end
end
\end{jllisting}
\caption{Non-redundant cover generation.}
\label{code:smart_covers}
\end{figure}

We have extracted the iterative superpose logic described above into its own function \jlinl{add_set!} to allow it to be performed on a cover-per-cover basis. This function is given in Figure~\ref{code:add_set}. This code is very different from the previous version, primarily in its use of a \textit{rank table}. The rank table is a dictionary mapping a closed set in $F$ to its assigned rank. This solves the problem that, while \pr{Superpose!} was getting more and more efficient, it was still performing the same comparisons over and over again.

In the previous versions, after adding the closed sets for a rank, \pr{Superpose!} was run to maintain the closed set properties of the matroid (given in Section~\ref{sec:matroid-theory}). These were maintained by ensuring that, for any two newly added sets $A,B \in \mathrm{F}[r+1]$, there exists $C \in \mathrm{F}[r]$ such that $A \cap B \subseteq C$. This was ensured by checking if the intersection of each such $A,B$ is contained in a set $C$ of rank $r$. We remember that one of the properties of the closed sets of a matroid is that the intersection of two closed sets is itself a closed set. Therefore, we do not need to find a closed set $C$ of rank $r$ that \textit{contains} $A \cap B$, since if $A$ and $B$ are indeed closed sets, their intersection will be \textit{equal} to some closed set $C$ of any rank $\leq r$. This insight leads us to the idea of the rank table: if we keep track of all added closed sets in a rank table, then we can memoize \pr{Superpose!} and replace the innermost loop with a constant time dictionary lookup. 

\jlinl{add_set!} accepts a closed set $X$ we are interested in assigning to rank $r$. It then loops through all existing rank-$r$ closed sets $Y$, ensuring that $X$ is either added as a closed set or merged with some existing closed set. When comparing a tentatively-closed set $X$ with an existing closed set $Y$, the function will encounter one of three possible situations:
\begin{enumerate}
  \item $X\cap Y$ is a closed set (it has an entry in the rank table) of rank less than $r$. Move on to the next closed set $Y$.
  \item $X\cap Y$ is a closed set (it has an entry in the rank table) of rank equal to $r$. This will for instance happen when $Y\subseteq X$. Remove $Y$ as a closed set and call \jlinl{add_set!} on $X \cup Y$.
  \item $X\cap Y$ has not been observed until this point. This happens when closed sets have been added of lower rank but similar cardinality, thus obscuring the rank of their subsets. Some additional checks are required:
  \begin{enumerate}
    \item[(a)] If $|X\cap Y| < r$, we know that the rank of $X\cap Y$ is less than $r$. Move on to the next closed set $Y$.
    \item[(b)] Otherwise, we need to see if $X\cap Y \subseteq Z$ for some $Z$ of lower rank, so we do the manual subset equality check with the lower-ranked closed set, as familiar from earlier implementations of \pr{Superpose!}.
  \end{enumerate}
\end{enumerate}

\begin{figure}
  \begin{jllisting}
function add_set!(x, F, r, rank, callback)
  for y in F[r+1]
    if haskey(rank, x&y) && rank[x&y]<r
      continue
    end

    if !haskey(rank, x&y)
      if Base.count_ones(x&y) < r
        continue
      else      
        r_ = check_rank(x&y, r, F)
        
        if r_ !== false
          rank[x&y] = r_
          continue
        end
      end
    end

    # x ‚à© y has rank > r, replace with x ‚à™ y.
    setdiff!(F[r+1], y)
    add_set!(x|y, F, r, rank, callback)
    return
  end

  push!(F[r+1], x)
  callback(x) # Sets rank[x] = r.
end

function check_rank(v, r, F)
  for (i, Fi) in enumerate(F[1:r]), z ‚àà Fi
    if v&z == v
      return i-1
    end
  end

  return false
end
  \end{jllisting}
  \caption{\jlinl{add_set!} adds a new closed set and runs the superpose logic.}
  \label{code:add_set}
\end{figure}

\begin{table}
  \centering
  \begin{tabular}{cccccc}
    \toprule
      $n$ & $(p_1, p_2, \ldots)$ & Trials & $r$   & Time    & Bytes allocated \\
    \midrule
      10  & (0, 6)    & 230040 & 4.03  & 260.9\unit{\us} & 27.092 KiB     \\
      10  & (0, 0, 6) & 59597  & 4.23  & 1.0ms           & 38.474 KiB     \\
      12  & (0, 7)    & 39753  & 5.03  & 1.5ms           & 68.219 KiB     \\
      12  & (0, 0, 7) & 7390   & 5.15  & 8.1ms           & 139.560 KiB     \\
      16  & (0, 8)    & 511    & 8.01  & 117.5ms         & 741.442 KiB     \\
      16  & (0, 0, 8) & 61     & 8.03  & 998.8ms         & 1.981 MiB     \\
      20  & (0, 9)    & 5      & 11.0  & 15.0s           & 14.217 MiB     \\
      20  & (0, 0, 9) & 1      & 11.0  & 108.8s          & 17.949 MiB     \\
      24  & (0, 10)   & 1      & 14.0  & 690.4s          & 75.663 MiB     \\
    \bottomrule
    \end{tabular}
  \caption{Performance of $\texttt{random\_knuth\_matroid}$ (version 5).}
  \label{tab:perf_v5}
\end{table}

Table~\ref{tab:perf_v5} shows the performance of \jlinl{random_knuth_matroid}, which is the fifth and final version discussed in this chapter. Comparing this with the initial performance depicted in Table~\ref{tab:perf_v1}, we can see that we are now able to generate somewhat larger matroids, on the order of a thousand times faster.

\subsection{Finding the properties of erected matroids}
The fact that \pr{Knuth-Matroid} fully enumerates all closed sets of the matroid as it erects it rank by rank begs the question: can we build the other families of sets for the matroids alongside the closed sets? In Appendix~\ref{apx:full-erection}, I describe an extension of \pr{Knuth-Matroid} that also fully enumerates $\mathcal{I}$ and $\mathcal{C}$ for $\mathfrak{M}$ when $n$ is small enough. Sadly, this approach does not scale well for larger values of $n$, as the size of these sets undergoes a combinatorial explosion as $n$ increases. 


\subsubsection{Determining matroid properties post-erection}
In a 1989 paper, Greene introduces the concept of \textit{descriptive sufficiency}~\cite{greene-1991}. A subcollection of closed sets of a matroid is descriptively sufficient if it can be used to identify the fundamental properties of the matroid using certain easily applied conditions. The collection of all closed sets of a matroid is one descriptively sufficient such collection. 

\paragraph{Rank function.} With every closed set of a matroid in hand, finding the rank of a set $S$ is simply a matter of finding the closed set $F$ of least rank such that $S\subseteq F$.

\begin{figure}
\begin{jllisting}
function rank(M::ClosedSetsMatroid, S::Integer)
  for (r, Fr) in enumerate(M.F), B ‚àà Fr
      if S&B == S return r-1 end
  end
end
\end{jllisting}
\end{figure}

\paragraph{Indepence oracle.} To check if a set $S$ is independent, we compare it with the closed sets of rank $|S|-1$. If $S$ is indeed independent, it cannot be a subset of a closed set of lower rank, so if we find one such set we return false. Otherwise, $S$ is independent.
\pagebreak
\begin{figure}
\begin{jllisting}
function is_indep(M::ClosedSetsMatroid, S::Integer)
  t = Base.count_ones(S)

  if t > length(M.F) return false end

  for F in M.F[t]
    if S&F==S return false end
  end

  return true
end
\end{jllisting}
\end{figure}

\paragraph{Closure function.} Determining the closure of a set $S$ in this case is the exact same procedure as finding the rank: the closed set $F$ of least rank such that $S\subseteq F$ is the closure of $S$.

\begin{figure}
\begin{jllisting}
function closure(M::ClosedSetsMatroid, S::Integer)
  for Fr in M.F, B ‚àà Fr
      if S&B == S return B end
  end
end
\end{jllisting}
\end{figure}